{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational modeling : RL algorithms in a virtual environment\n",
    "\n",
    "Question : under very low amounts of evidence, how do human sample a complex action space ? Can we infer some form of structure in this exploration ? Can Active Inference provide some answers regarding the mechanistic processes behind it ?\n",
    "\n",
    "\n",
    "\n",
    "First, we grab the data corresponding to the experiment we're interested in (here, experiment 002). We also remove the subjects that either had technical issues or had very suspicious results. *(we should provide a clear rule on subject exclusion here, maybe based on action variance across all dimensions or reaction times ?).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annic\\OneDrive\\Bureau\\MainPhD\\code\\behavioural_exp_code\\exploit_results_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the needed packages \n",
    "# \n",
    "# 1/ the usual suspects\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jax import vmap\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# 2/ The Active Inference package \n",
    "import actynf\n",
    "from actynf.jaxtynf.jax_toolbox import _normalize,_jaxlog\n",
    "\n",
    "# 3/ Tools for : \n",
    "# a. Getting the raw data : \n",
    "from database_handling.database_extract import get_all_subject_data_from_internal_task_id\n",
    "from utils import remove_by_indices\n",
    "# b. Preprocessing the data :\n",
    "from analysis_tools.preprocess import OPTIONS_PREPROCESS_DEFAULT,get_preprocessed_data\n",
    "\n",
    "\n",
    "\n",
    "# We define the environment as a state machine that outputs a feedback \n",
    "# every time an action is given to it : \n",
    "from actynf.jaxtynf.layer_process import initial_state_and_obs,process_update\n",
    "from actynf.jaxtynf.shape_tools import vectorize_weights\n",
    "\n",
    "\n",
    "# The environment is statically defined by its HMM matrices : \n",
    "from hmm_weights import behavioural_process\n",
    "\n",
    "# For the active inference model : \n",
    "from hmm_weights import basic_latent_model\n",
    "\n",
    "from actynf.jaxtynf.layer_trial import compute_step_posteriors\n",
    "from actynf.jaxtynf.layer_learn import learn_after_trial\n",
    "from actynf.jaxtynf.layer_options import get_learning_options,get_planning_options\n",
    "\n",
    "from actynf.jaxtynf.shape_tools import to_log_space,get_vectorized_novelty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Trial 0----\n",
      "0 [Array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] -0.22222221\n",
      "2 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "3 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111134\n",
      "4 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.33333334\n",
      "5 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.44444448\n",
      "6 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "7 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.33333334\n",
      "8 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "9 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111112\n",
      "10 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.11111112\n",
      "----\n",
      "----Trial 1----\n",
      "0 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "2 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "3 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.44444448\n",
      "4 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.33333334\n",
      "5 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "6 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "7 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111112\n",
      "8 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.11111112\n",
      "9 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111112\n",
      "10 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222222\n",
      "----\n",
      "----Trial 2----\n",
      "0 [Array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.33333334\n",
      "2 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111112\n",
      "3 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.11111112\n",
      "4 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "5 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111112\n",
      "6 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222222\n",
      "7 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.111111134\n",
      "8 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "9 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.33333337\n",
      "10 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "----\n",
      "----Trial 3----\n",
      "0 [Array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.33333334\n",
      "2 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "3 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.111111134\n",
      "4 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "5 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] -0.111111104\n",
      "6 [Array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)] 0.22222221\n",
      "7 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] -0.22222221\n",
      "8 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111134\n",
      "9 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.111111134\n",
      "10 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "----\n",
      "----Trial 4----\n",
      "0 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111112\n",
      "2 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "3 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.33333337\n",
      "4 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "5 [Array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)] 0.111111104\n",
      "6 [Array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)] 0.0\n",
      "7 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] -0.22222221\n",
      "8 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "9 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.33333334\n",
      "10 [Array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)] 0.44444445\n",
      "----\n",
      "----Trial 5----\n",
      "0 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222222\n",
      "2 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "3 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111104\n",
      "4 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "5 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111104\n",
      "6 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "7 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "8 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.0\n",
      "9 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "10 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222222\n",
      "----\n",
      "----Trial 6----\n",
      "0 [Array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.11111111\n",
      "2 [Array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111111\n",
      "3 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.5555556\n",
      "4 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111134\n",
      "5 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "6 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "7 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222222\n",
      "8 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222222\n",
      "9 [Array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "10 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "----\n",
      "----Trial 7----\n",
      "0 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111111\n",
      "2 [Array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111111\n",
      "3 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.33333334\n",
      "4 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.111111104\n",
      "5 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222222\n",
      "6 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "7 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.33333337\n",
      "8 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111134\n",
      "9 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.111111134\n",
      "10 [Array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)] 0.22222221\n",
      "----\n",
      "----Trial 8----\n",
      "0 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.11111111\n",
      "2 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.11111111\n",
      "3 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "4 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "5 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "6 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "7 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "8 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "9 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.44444448\n",
      "10 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "----\n",
      "----Trial 9----\n",
      "0 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "1 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "2 [Array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)] -0.22222224\n",
      "3 [Array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)] 0.22222224\n",
      "4 [Array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)] 0.5555556\n",
      "5 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.44444445\n",
      "6 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.111111134\n",
      "7 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111134\n",
      "8 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] 0.0\n",
      "9 [Array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)] 0.111111134\n",
      "10 [Array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)] -0.111111134\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# To generate synthetic data :\n",
    "from simulate.generate_observations import TrainingEnvironment,run_loop,generate_synthetic_data\n",
    "\n",
    "T = 11\n",
    "\n",
    "# ENVIRONMENTAL CONSTANTS :\n",
    "N_FEEDBACK_OUTCOMES = 10\n",
    "TRUE_FEEDBACK_STD = 0.15\n",
    "GRID_SIZE = (7,7)\n",
    "START_COORD = [[5,1],[5,2],[4,1]]\n",
    "END_COORD = [0,6]\n",
    "\n",
    "# The weights of the HMM environment\n",
    "(a,b,c,d,e,u),fb_vals = behavioural_process(GRID_SIZE,START_COORD,END_COORD,N_FEEDBACK_OUTCOMES,TRUE_FEEDBACK_STD)\n",
    "\n",
    "rngkey = jax.random.PRNGKey(np.random.randint(0,10))\n",
    "env = TrainingEnvironment(rngkey,a,b,c,d,e,u,T)\n",
    "    \n",
    "for k in range(10):\n",
    "    print(\"----Trial {}----\".format(k))\n",
    "    o,r,end_trial,t = env.reinit_trial()\n",
    "    print(t,o,r)\n",
    "    while not(end_trial) :\n",
    "        action = jax.nn.one_hot(1,9)\n",
    "        o,r,end_trial,t = env.step(action)\n",
    "        print(t,o,r)\n",
    "    print(\"----\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put all the models we are going to fit in an equal footing, we will assume a discretized action space along the 3 dimensions previously mentionned for all of them. To study the effect of not making this crucial hypothesis, we refer the reader to the Reinforcment Learning part of this study. \n",
    "\n",
    "Reward definition : we will assume that agents perceive changes in the level of the gauge as a reward signal.\n",
    "\n",
    "Here, we will study the following models : \n",
    "### Blind models - the action does not depend on the stimuli at all\n",
    "1. A random action model that selects actions randomly and does not learn\n",
    "2. A choice kernel model that repeats actions it already performed :  $CK_{t+1}(u) = CK_{t}(u) + \\alpha_c (a_t - CK_{t}(u))$ where $a_t$ is 1 if $u$ was selcted and 0.0 otherwise. $P_t(u) = \\sigma(\\beta_c CK_{t})$\n",
    "### Stateless models - the action does not depend on the level of the gauge but only on the reward\n",
    "3. A Rescorla-Wagner model - stateless that attempts to learn the value of a specific action by updating the perceived reward attached to it : $Q_{t+1}(u) = Q_{t}(u) + \\alpha (r_t - Q_{t}(u))$  (Wilson RC, Collins AG. Ten simple rules for the computational modeling of behavioral data. Elife. 2019 Nov 26;8:e49547. doi: 10.7554/eLife.49547. PMID: 31769410; PMCID: PMC6879303.). Actions are selected through a tempered softmax following : $P_t(u) = \\sigma(\\beta Q_{t})$. The free parameters for this model are $\\alpha$ and $\\beta$.\n",
    "4. A mix of the previous 2 models : $P_t(u) = \\sigma(\\beta Q_{t} + \\beta_c CK_{t})$\n",
    "### Stateful models - the action depends on the level of the gauge as well as the reward\n",
    "5. A tabular Q-learning agent : $Q_{t+1}(u,s) = Q_{t}(u,s) + \\alpha (r_t - Q_{t}(u,s))$ with different learning rates for positive and negative feedbacks $\\{\\alpha_-,\\alpha_+\\}$ with a choice temperature $\\beta$.\n",
    "6. A vesion of this agent that takes into account the choice Kernel described previously\n",
    "### Bayesian Active Inference models - The reward is not taken into account. The level of the gauge is interpreted as an indicator regarding a true (hidden) state of the system\n",
    "7. A single dimension model (\"How far am I from my goal ?\") with various subcategories of models : \n",
    "    - A naive q learning like model  with low amounts of states\n",
    "    - A more advanced model that features the ability to generalize between states\n",
    "    - An even more advanced model that also features the ability to generalize between actions\n",
    "8. A bidimensionnal model (\"Where am I in the grid ? Where is my goal ?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Because we have a much more complex intuition behind what is happening but with a pretty hard-to-derive likelihood function, we should look at Simulation Based Inference (see https://elifesciences.org/articles/56261#s4,https://astroautomata.com/blog/simulation-based-inference/,Artificial neural networks for model identification and parameter estimation in computational cognitive models, Milena Rmus ,Ti-Fen Pan,Liyu Xia,Anne G. E. Collins, Published: May 15, 2024; https://doi.org/10.1371/journal.pcbi.1012119 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any difference between the two ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Trial 1\n",
      "Trial 2\n",
      "Trial 3\n",
      "Trial 4\n",
      "Trial 5\n",
      "Trial 6\n",
      "Trial 7\n",
      "Trial 8\n",
      "Trial 9\n",
      "(10, 10, 9)\n"
     ]
    }
   ],
   "source": [
    "from agents import random_agent\n",
    "\n",
    "# In : an agent based on some hyperparameters : \n",
    "SEED = 100\n",
    "NTRIALS = 10\n",
    "random_agent_hyperparameters = None\n",
    "random_agent_constants = (9,)\n",
    "\n",
    "params_final,training_hist = run_loop(env,random_agent(random_agent_hyperparameters,random_agent_constants),SEED,NTRIALS)\n",
    "print(jnp.array(training_hist[\"actions\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Trial 1\n",
      "Trial 2\n",
      "Trial 3\n",
      "Trial 4\n",
      "Trial 5\n",
      "Trial 6\n",
      "Trial 7\n",
      "Trial 8\n",
      "Trial 9\n"
     ]
    }
   ],
   "source": [
    "from agents import choice_kernel_agent\n",
    "\n",
    "ck_agent_hyperparameters = (0.5,1.0)\n",
    "ck_agent_constants = (9,)\n",
    "\n",
    "params_final,training_hist = run_loop(env,choice_kernel_agent(ck_agent_hyperparameters,ck_agent_constants),SEED,NTRIALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Trial 1\n",
      "Trial 2\n",
      "Trial 3\n",
      "Trial 4\n",
      "Trial 5\n",
      "Trial 6\n",
      "Trial 7\n",
      "Trial 8\n",
      "Trial 9\n"
     ]
    }
   ],
   "source": [
    "from agents import rescorla_wagner_agent\n",
    "\n",
    "rw_agent_hyperparameters = (0.5,1.0)\n",
    "rw_agent_constants = (9,)\n",
    "\n",
    "params_final,training_hist = run_loop(env,rescorla_wagner_agent(rw_agent_hyperparameters,rw_agent_constants),SEED,NTRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Trial 1\n",
      "Trial 2\n",
      "Trial 3\n",
      "Trial 4\n",
      "Trial 5\n",
      "Trial 6\n",
      "Trial 7\n",
      "Trial 8\n",
      "Trial 9\n"
     ]
    }
   ],
   "source": [
    "from agents import rw_ck_agent\n",
    "\n",
    "rw_ck_agent_hyperparameters = (0.1,0.5,0.5,0.1)\n",
    "rw_ck_agent_constants = (9,)\n",
    "\n",
    "params_final,training_hist = run_loop(env,rw_ck_agent(rw_ck_agent_hyperparameters,rw_ck_agent_constants),SEED,NTRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Trial 1\n",
      "Trial 2\n",
      "Trial 3\n",
      "Trial 4\n",
      "Trial 5\n",
      "Trial 6\n",
      "Trial 7\n",
      "Trial 8\n",
      "Trial 9\n"
     ]
    }
   ],
   "source": [
    "from agents import q_learning_agent\n",
    "\n",
    "ql_ck_agent_hyperparameters = (0.5,0.7,1.0,0.0,0.0)\n",
    "ql_ck_agent_constants = (9,N_FEEDBACK_OUTCOMES)\n",
    "\n",
    "params_final,training_hist = run_loop(env,q_learning_agent(ql_ck_agent_hyperparameters,ql_ck_agent_constants),SEED,NTRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 1\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 2\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 3\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 4\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 5\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 6\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 7\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 8\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 9\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 10\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 11\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 12\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 13\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 14\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 15\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 16\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 17\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 18\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 19\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 20\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 21\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 22\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 23\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 24\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 25\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 26\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 27\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 28\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 29\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 30\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 31\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 32\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 33\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 34\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 35\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 36\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 37\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 38\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 39\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 40\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 41\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 42\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 43\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 44\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 45\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 46\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 47\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 48\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 49\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 50\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 51\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 52\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 53\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 54\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 55\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 56\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 57\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 58\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 59\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 60\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 61\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 62\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 63\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 64\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 65\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 66\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 67\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 68\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 69\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 70\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 71\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 72\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 73\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 74\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 75\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 76\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 77\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 78\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 79\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 80\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 81\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 82\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 83\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 84\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 85\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 86\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 87\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 88\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 89\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 90\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 91\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 92\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 93\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 94\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 95\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 96\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 97\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 98\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "Trial 99\n",
      "(10,)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "[Array([[[  4.4283676,   6.479962 ,  24.643738 ,  13.246692 ,\n",
      "           5.3858147,   4.980901 ,   6.6415215,   5.264242 ,\n",
      "           4.81544  ],\n",
      "        [  2.2216916,   3.2784886,  12.668909 ,   8.041651 ,\n",
      "           2.2409031,   2.7250428,   3.5234303,   2.1071591,\n",
      "           1.7645516],\n",
      "        [  1.1933392,   1.5157151,   3.138499 ,   2.6201372,\n",
      "           1.3858964,   1.2645681,   1.4595587,   1.0267954,\n",
      "           1.0282627],\n",
      "        [  1.0320251,   1.0171595,   1.2040999,   1.082205 ,\n",
      "           1.3297269,   1.0040746,   1.0121334,   1.0013727,\n",
      "           1.0012151],\n",
      "        [  1.0021594,   1.001934 ,   1.0089977,   1.0032017,\n",
      "           1.01228  ,   1.001432 ,   1.0019397,   1.0009887,\n",
      "           1.0006418]],\n",
      "\n",
      "       [[  2.9289863,   5.635344 ,  42.72355  ,   9.879906 ,\n",
      "           6.0923243,   1.8128381,   3.0488443,   1.873905 ,\n",
      "           2.1741598],\n",
      "        [  3.8229969,   7.5197434,  59.579395 ,  32.4893   ,\n",
      "           5.2709646,   3.6439617,   5.2219744,   4.114587 ,\n",
      "           4.175302 ],\n",
      "        [  2.0516095,   2.9706237,  21.298407 ,  19.904142 ,\n",
      "           2.1146765,   1.9083754,   2.275836 ,   1.4396181,\n",
      "           1.446188 ],\n",
      "        [  1.4457252,   1.216608 ,   2.535296 ,   5.00737  ,\n",
      "           1.3268595,   1.1514336,   1.1779214,   1.0106533,\n",
      "           1.012465 ],\n",
      "        [  1.0572907,   1.0092757,   1.0915096,   1.1333177,\n",
      "           1.1292493,   1.0032725,   1.0055792,   1.0011834,\n",
      "           1.0014203]],\n",
      "\n",
      "       [[  1.2229131,   3.2560508,  22.808208 ,   3.919957 ,\n",
      "           3.0732272,   1.0073456,   1.8304098,   1.0125471,\n",
      "           1.1493509],\n",
      "        [  1.8281038,   5.305112 ,  87.09718  ,  23.14772  ,\n",
      "           4.1866794,   1.3099389,   1.9844012,   1.345082 ,\n",
      "           1.5671935],\n",
      "        [  2.9296703,   5.0267696, 106.60124  ,  80.31969  ,\n",
      "           3.7076092,   2.9984086,   3.2818267,   2.7789521,\n",
      "           2.81005  ],\n",
      "        [  1.697228 ,   1.7421829,  31.744316 ,  42.791367 ,\n",
      "           1.422024 ,   1.6626335,   1.4767925,   1.1617483,\n",
      "           1.1643403],\n",
      "        [  1.2030926,   1.0820527,   2.621984 ,   8.671398 ,\n",
      "           1.1219257,   1.0648844,   1.0657927,   1.0039371,\n",
      "           1.0047204]],\n",
      "\n",
      "       [[  1.0018355,   1.7011652,   3.4949446,   1.2089497,\n",
      "           1.01614  ,   1.001053 ,   1.0899664,   1.0008233,\n",
      "           1.001871 ],\n",
      "        [  1.0831177,   2.4585721,  25.0897   ,   5.7771807,\n",
      "           1.7797121,   1.0034493,   1.3752832,   1.0051987,\n",
      "           1.0562478],\n",
      "        [  1.3072692,   2.9538584, 105.38168  ,  44.755424 ,\n",
      "           2.1795595,   1.1264126,   1.5904403,   1.1269712,\n",
      "           1.2087756],\n",
      "        [  2.3479238,   3.1243093, 133.07112  , 119.1175   ,\n",
      "           2.628974 ,   2.3775976,   2.709992 ,   2.2865613,\n",
      "           2.2980027],\n",
      "        [  1.2572402,   1.2740111,  50.04135  ,  58.18193  ,\n",
      "           1.1552968,   1.2440573,   1.1853718,   1.0595043,\n",
      "           1.0604585]],\n",
      "\n",
      "       [[  1.0009234,   1.0268952,   1.4628497,   1.0111539,\n",
      "           1.001649 ,   1.0008018,   1.0031234,   1.000604 ,\n",
      "           1.0007988],\n",
      "        [  1.0011424,   1.28086  ,   3.3249512,   1.380079 ,\n",
      "           1.0074116,   1.0008898,   1.0363444,   1.0008082,\n",
      "           1.0012969],\n",
      "        [  1.03114  ,   1.5477757,  26.452898 ,   9.712708 ,\n",
      "           1.2879252,   1.0016901,   1.2874337,   1.0019314,\n",
      "           1.0207795],\n",
      "        [  1.1142035,   1.7191187, 105.524155 ,  52.77657  ,\n",
      "           1.4342755,   1.0467823,   1.5643044,   1.0467107,\n",
      "           1.0768054],\n",
      "        [  2.128142 ,   2.4136465, 149.27504  ,  89.01989  ,\n",
      "           2.2313998,   2.1389186,   2.2760165,   2.1054206,\n",
      "           2.1096299]]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents import active_inference_basic_1D\n",
    "\n",
    "# We get a model weights by defining a \"parameters\" object :\n",
    "aif_1d_constants = {\n",
    "    # General environment : \n",
    "    \"N_feedback_ticks\":N_FEEDBACK_OUTCOMES,\n",
    "    # Latent state space structure\n",
    "    \"Ns_latent\":5,      # For 1D\n",
    "    # Action discretization:\n",
    "    \"N_actions_distance\" :3,\n",
    "    \"N_actions_position\" :9,\n",
    "    \"N_actions_angle\" :9,\n",
    "    \n",
    "    \"Th\" : 3\n",
    "}\n",
    "\n",
    "aif_1d_params = {    \n",
    "    # ----------------------------------------------------------------------------------------------------\n",
    "    # Model parameters : these should interact with the model components in a differentiable manner\n",
    "    \"transition_concentration\": 1.0,\n",
    "    \"transition_stickiness\": 1.0,\n",
    "    \"transition_learning_rate\" : 1.0,\n",
    "    \"state_interpolation_temperature\" : 1.0,\n",
    "    \n",
    "    \"initial_state_concentration\": 1.0,\n",
    "    \n",
    "    \"feedback_expected_std\" : 0.15,\n",
    "    \"emission_concentration\" : 1.0,\n",
    "    \"emission_stickiness\" : 100.0,\n",
    "    \n",
    "    \"reward_seeking\" : 10.0,\n",
    "    \n",
    "    \"action_selection_temperature\" : 10.0,\n",
    "}\n",
    "\n",
    "a0,b0,c0,d0,e0,u = basic_latent_model({**aif_1d_constants, **aif_1d_params})\n",
    "\n",
    "NTRIALS = 100\n",
    "params_final,training_hist = run_loop(env,active_inference_basic_1D(aif_1d_params,aif_1d_constants),SEED,NTRIALS)\n",
    "\n",
    "a,b,c,d,e,u = params_final\n",
    "\n",
    "\n",
    "nu = u.shape[0]\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(2,nu)\n",
    "print(b)\n",
    "for act in range(nu):\n",
    "    ax = axs[0,act]\n",
    "    ax.imshow(b0[0][...,act])\n",
    "    \n",
    "    ax = axs[1,act]\n",
    "    ax.imshow(b[0][...,act])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we have all of our proposal models.  However, we aim at performing model inversion based on task data ! This means that we're going to need **likelihood functions** for each of these models !\n",
    "\n",
    "Likelihood function describe the probability of these models generating the observed actions, given their hyperparameters $\\theta$ and their previous experiences $o_{1:T,1:t},s_{1:T,1:t}$ : \n",
    "$$\n",
    "\\sum_T \\sum_{t\\in T} P(u_t|o_{1:T,1:t},u_{1:T,1:t-1},\\theta)\n",
    "$$\n",
    "\n",
    "In the next notebook, we'll derive these functions from the models shown here !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploit_results_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
