{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annic\\OneDrive\\Bureau\\MainPhD\\code\\behavioural_exp_code\\exploit_results_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Loaded the task results for study 6703ab18d345eaa4893587e0 \n",
      "    (49 subjects.)\n",
      " - Loaded the task results for study 66f9aee8210357265a5958fc \n",
      "    (50 subjects.)\n",
      " - Loaded the task results for study 6703ab1a7ea30557549dc6da \n",
      "    (50 subjects.)\n",
      "Total : 149 subjects\n",
      "145 subjects remaining after removing problematic subjects.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import plotly as pltly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# + local functions : \n",
    "from database_handling.database_extract import get_all_subject_data_from_internal_task_id\n",
    "from utils import remove_by_indices\n",
    "from analysis_tools.preprocess import get_preprocessed_data_from_df\n",
    "\n",
    "from simulate.compute_likelihood import fit_map_agent,compute_loglikelihood\n",
    "\n",
    "from agents import choice_kernel_agent,random_agent,rescorla_wagner_agent,rw_ck_agent,q_learning_agent,active_inference_basic_1D\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "import jax.random as jr\n",
    "from jax import vmap\n",
    "\n",
    "# Except subjects for predictors :\n",
    "problematic_subjects_misc = [\"611d60c383f4f70ff4bc99fd\", # S2 : Did the task twice \n",
    "                             \"66a74bdfdcaccdc0703894d5\", # Subjects with consent revoked \n",
    "                            \"667d92f2ea5c1542f417285d\",\n",
    "                            \"6548f570022275786186ffbd\"]\n",
    "\n",
    "# Import the data from the remote mongodb database & the imported prolific demographics :\n",
    "INTERNAL_TASK_ID = \"003\"\n",
    "# Study 2 : the std of the was 0.025,0.1 and 0.175\n",
    "PROLIFIC_STUDY_IDs = [\"6703ab18d345eaa4893587e0\",\"66f9aee8210357265a5958fc\",\"6703ab1a7ea30557549dc6da\"]\n",
    "\n",
    "TASK_RESULTS_ALL = []\n",
    "for prolific_study_id in PROLIFIC_STUDY_IDs:\n",
    "    task_results = get_all_subject_data_from_internal_task_id(INTERNAL_TASK_ID,prolific_study_id,\n",
    "                                                              process_feedback_data_stream=True,override_save=False)\n",
    "    print(\" - Loaded the task results for study {} \\n    ({} subjects.)\".format(prolific_study_id,len(task_results)))\n",
    "    TASK_RESULTS_ALL += task_results\n",
    "print(\"Total : {} subjects\".format(len(TASK_RESULTS_ALL)))\n",
    "\n",
    "# Each subject in task results has the following entries : \n",
    "# TASK_RESULT_FEATURES, TASK_RESULTS_EVENTS, TASK_RESULTS_DATA, TASK_RESULTS,RT_FB\n",
    "remove_these_subjects = []\n",
    "for index,entry in enumerate(TASK_RESULTS_ALL):\n",
    "    subj_dict,_,_,_ = entry\n",
    "    subj_name = subj_dict[\"subject_id\"]\n",
    "    if subj_name in problematic_subjects_misc:\n",
    "        remove_these_subjects.append(index)\n",
    "\n",
    "TASK_RESULTS = remove_by_indices(TASK_RESULTS_ALL,remove_these_subjects)\n",
    "print(str(len(TASK_RESULTS)) + \" subjects remaining after removing problematic subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 33/15950 actions were missed. (0.21 %)\n"
     ]
    }
   ],
   "source": [
    "# The initial datframe is the first tuple in our task result list of tuples : \n",
    "subjects_df = pd.DataFrame([entry[0] for entry in TASK_RESULTS])\n",
    "\n",
    "# Avoid too many categories : \n",
    "subjects_df['Sex'] = np.where(subjects_df['Sex'].isin(['Male','Female']), subjects_df['Sex'], 'Other')\n",
    "\n",
    "category_counts = subjects_df['Nationality'].value_counts()\n",
    "threshold = 2\n",
    "subjects_df['Nationality_red'] = subjects_df['Nationality'].apply(lambda x: x if category_counts[x] >= threshold else 'Other')\n",
    "\n",
    "# There was a single noise term for the whole training for each subject : \n",
    "subject_noise_parameters = [np.array(entry[2][\"parameters\"][\"noise_int\"])[0] for entry in TASK_RESULTS]\n",
    "\n",
    "# We add it to the df : \n",
    "subjects_df[\"feedback_noise_std\"] = subject_noise_parameters\n",
    "\n",
    "# # Create a pandas dataframe from the list of subject dictionnaries :\n",
    "\n",
    "# In this dataframe, we're interested in sotring various kinds of data from the trials : \n",
    "# 1/ Data from the instruction phase\n",
    "\n",
    "# 2/ Data from the feedback gauge :\n",
    "# Timestep values :\n",
    "all_subject_scores = [subjdata[2][\"scoring\"] for subjdata in TASK_RESULTS]\n",
    "subjects_df[\"raw_feedback_values\"] = [subj_scores[\"feedback\"] for subj_scores in all_subject_scores]\n",
    "# Real time gauge values :\n",
    "subjects_df[\"realtime_values\"] = [subjdata[3][1] for subjdata in TASK_RESULTS] # Each element is a list of list os arrays (with varying shape)\n",
    "\n",
    "# 3/ Data from the hidden grid :\n",
    "# The grid for a specific trial: \n",
    "trial_grids = [entry[2][\"process\"][\"grids\"] for entry in TASK_RESULTS]\n",
    "subjects_df[\"grid_layout\"] = trial_grids\n",
    "# Position value :\n",
    "subject_positions = [entry[2][\"process\"][\"positions\"] for entry in TASK_RESULTS]\n",
    "subjects_df[\"subject_positions\"] = subject_positions\n",
    "\n",
    "goal_positions = [np.array(entry[2][\"parameters\"][\"goal_pos\"])[:,0,:] for entry in TASK_RESULTS]\n",
    "subjects_df[\"goal_position\"] = goal_positions\n",
    "\n",
    "def euclidian_distance(position,goal):\n",
    "    return jnp.linalg.norm(position-goal,2)\n",
    "gs = trial_grids[0][0].shape\n",
    "maximum_euclidian_dist = euclidian_distance(jnp.array(gs) - jnp.ones((2,)),jnp.zeros((2,)))\n",
    "all_euclidian_distances = vmap(vmap(vmap(euclidian_distance,in_axes=(0,None))))(jnp.array(subject_positions),jnp.array(goal_positions))/maximum_euclidian_dist\n",
    "subjects_df[\"norm_distance_to_goal\"] = list(all_euclidian_distances)\n",
    "\n",
    "\n",
    "# 4/ Data from the realized actions :\n",
    "\n",
    "# Actions performed : this encompasses the points dropped\n",
    "# But may also include temporal elements such as :\n",
    "# - the time taken to perform an actions (first point / second point)\n",
    "# - when the action was performed with regard to the gauge\n",
    "canvas_size = TASK_RESULTS[0][0][\"canvas_size\"] # Constant across all subjects + conditions\n",
    "all_actions_data = np.stack([subjdata[2][\"blanket\"][\"actions\"] for subjdata in TASK_RESULTS]).astype(float)\n",
    "\n",
    "Nsubj,Ntrials,Nactions,Npoints,Nfeatures = all_actions_data.shape\n",
    "# print(all_actions_data)\n",
    "# Normalize the point data :\n",
    "all_actions_data[...,0] = all_actions_data[...,0]/canvas_size[0]\n",
    "all_actions_data[...,1] = 1.0 - all_actions_data[...,1]/canvas_size[1]\n",
    "\n",
    "\n",
    "# First, let's get a mask for all actions that were NOT performed :\n",
    "mask = all_actions_data[...,-1]==1  # values are 1 if the point was recorded\n",
    "both_points_only = (mask[...,0] & mask[...,1])\n",
    "     # All points where at least one value is missing\n",
    "\n",
    "Nactions = all_actions_data[...,0,0].size\n",
    "Nmissed_actions = (~both_points_only).sum()\n",
    "print(\"A total of {}/{} actions were missed. ({:.2f} %)\".format(Nmissed_actions,Nactions,100*Nmissed_actions/Nactions))\n",
    "\n",
    "subjects_df[\"raw_points\"] = list(all_actions_data)\n",
    "\n",
    "\n",
    "# Encoded barycenters :\n",
    "barycenter_x = (all_actions_data[...,0,0]+all_actions_data[...,1,0])/2.0\n",
    "barycenter_y = (all_actions_data[...,0,1]+all_actions_data[...,1,1])/2.0\n",
    "barycenters = np.stack([barycenter_x,barycenter_y],axis=-1)\n",
    "subjects_df[\"action_barycenters\"] = list(barycenters)\n",
    "\n",
    "# Encoded euclidian distance between points :\n",
    "action_distances = np.linalg.norm(all_actions_data[...,0,:2]-all_actions_data[...,1,:2],axis=-1)\n",
    "subjects_df[\"action_distances\"] = list(action_distances)\n",
    "\n",
    "# Encoded evolution of point angles :\n",
    "angles = np.atan2(all_actions_data[...,1,1]-all_actions_data[...,0,1],all_actions_data[...,1,0]-all_actions_data[...,0,0])\n",
    "subjects_df[\"action_angles\"] = list(angles)\n",
    "\n",
    "# Encoded delays between stimuli, point1 and point2 :\n",
    "all_action_delays = all_actions_data[...,-1,2]\n",
    "unfit_actions = (all_action_delays<10)\n",
    "subjects_df[\"action_time_between_points\"] = np.where(all_action_delays>10, all_action_delays, np.nan).tolist()\n",
    "\n",
    "# Performance metric : we use the average distance to goal state across the lask k_T trials and the last k_t timesteps : (ignoring the blind trial)\n",
    "last_k_trials,last_t_timesteps = 3,5\n",
    "all_distances_to_goal = np.mean(np.stack(subjects_df[\"norm_distance_to_goal\"])[:,-last_k_trials:-1,-last_t_timesteps:],axis=(-1,-2))\n",
    "subjects_df[\"final_performance\"] = (1.0 - all_distances_to_goal).tolist()\n",
    "\n",
    "\n",
    "# And for the blind trial :\n",
    "blind_trial_distances_to_goal = np.mean(np.stack(subjects_df[\"norm_distance_to_goal\"])[:,-1,-last_t_timesteps:],axis=(-1))\n",
    "subjects_df[\"blind_trial_performance\"] = (1.0 - blind_trial_distances_to_goal).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of the 15950.0 actions performed by our subjects, 15917.0 were 'valid' (99.8 %)\n",
      "Out of the 15950.0 feedback sequences potentially observed by our subjects, 15950 were 'valid' (100.0 %)\n",
      "     -> Agent : random\n",
      "     -> Agent : rw\n",
      "step 0, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([197.32918, 212.4399 , 212.47246, 212.47235, 210.83157, 211.8431 ,\n",
      "       198.66756, 212.3359 , 277.167  , 205.005  , 200.20853, 210.50194,\n",
      "       212.123  , 212.36821, 212.47244, 212.47005, 212.47234, 212.47234,\n",
      "       212.4724 , 199.39818, 211.75491, 277.3604 , 212.47237, 210.6917 ,\n",
      "       212.47202, 210.63918, 212.45895, 212.24612, 211.23232, 212.47246,\n",
      "       212.47246, 212.42912, 212.24966, 212.47246, 210.57492, 212.47246,\n",
      "       206.48024, 211.1489 , 211.96234, 212.38484, 212.47202, 212.47174,\n",
      "       206.35751, 210.49788, 211.5727 , 212.47244, 212.39227, 227.00682,\n",
      "       254.67734, 211.65617], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 10, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([196.19145, 212.38289, 212.47246, 212.47218, 210.68274, 211.53177,\n",
      "       197.51038, 211.95866, 268.3624 , 199.9475 , 198.59085, 210.47357,\n",
      "       211.51573, 212.134  , 212.47243, 212.46584, 212.47208, 212.47235,\n",
      "       212.47232, 198.9866 , 210.71364, 268.7567 , 212.47223, 210.23866,\n",
      "       212.47104, 210.05379, 212.43509, 211.89061, 209.23802, 212.47246,\n",
      "       212.47246, 212.35347, 212.04172, 212.47246, 210.50533, 212.47246,\n",
      "       203.03726, 210.90263, 211.61935, 212.23407, 212.47092, 212.47063,\n",
      "       203.38681, 208.34529, 211.3094 , 212.47226, 212.24985, 220.95898,\n",
      "       246.92638, 211.23962], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 20, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.60095, 212.20811, 212.47246, 212.4716 , 210.57727, 211.26369,\n",
      "       196.54297, 210.75061, 259.5099 , 198.26636, 197.99919, 210.47253,\n",
      "       210.01115, 211.39986, 212.4724 , 212.45293, 212.47107, 212.47223,\n",
      "       212.4723 , 199.01491, 208.52522, 260.4773 , 212.4719 , 209.12448,\n",
      "       212.4681 , 208.54756, 212.36093, 211.58112, 205.84735, 212.47246,\n",
      "       212.47246, 212.12338, 211.76178, 212.47246, 210.47627, 212.47246,\n",
      "       200.47366, 210.60956, 211.28778, 211.78954, 212.46727, 212.46495,\n",
      "       200.98915, 205.27234, 211.07898, 212.47224, 211.82825, 215.57385,\n",
      "       239.60948, 210.4494 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 30, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.32611, 211.6195 , 212.47246, 212.46712, 210.50972, 211.03378,\n",
      "       195.89227, 207.73267, 249.7578 , 198.06693, 197.05943, 210.46849,\n",
      "       206.99226, 209.37135, 212.47226, 212.40927, 212.46762, 212.47157,\n",
      "       212.47208, 198.98738, 205.11554, 252.56616, 212.4689 , 205.83649,\n",
      "       212.45728, 204.42714, 212.09923, 211.32013, 202.19833, 212.47246,\n",
      "       212.47246, 211.36763, 211.44809, 212.47244, 210.47238, 212.47246,\n",
      "       199.21391, 209.99202, 210.877  , 210.45863, 212.45407, 212.42981,\n",
      "       199.60179, 202.20949, 210.88982, 212.47076, 210.55333, 210.9707 ,\n",
      "       232.81187, 208.25226], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 40, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.24203, 209.73743, 212.47246, 212.44196, 210.45844, 210.80902,\n",
      "       195.51309, 203.33412, 236.07445, 197.63345, 196.39565, 210.4544 ,\n",
      "       203.14703, 205.54268, 212.47166, 212.26736, 212.45297, 212.4686 ,\n",
      "       212.47058, 198.9885 , 201.77779, 244.9864 , 212.45242, 199.47275,\n",
      "       212.41183, 198.33572, 211.13046, 211.1054 , 199.888  , 212.47243,\n",
      "       212.4724 , 209.11417, 211.08418, 212.47232, 210.47247, 212.47241,\n",
      "       198.82692, 207.88503, 209.99413, 207.28265, 212.39883, 212.18158,\n",
      "       199.07828, 200.1513 , 210.73473, 212.46184, 207.44623, 207.21872,\n",
      "       226.59708, 202.89363], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 50, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23267, 205.66243, 212.47246, 212.29755, 210.35045, 210.43329,\n",
      "       195.32999, 200.18414, 213.6499 , 197.4003 , 195.84274, 210.38889,\n",
      "       200.34929, 201.61436, 212.46872, 211.93716, 212.38306, 212.45442,\n",
      "       212.4637 , 198.98695, 199.7877 , 237.3488 , 212.35872, 195.94469,\n",
      "       212.19896, 195.58919, 208.18016, 210.93175, 198.9995 , 212.47232,\n",
      "       212.4723 , 204.82837, 210.33258, 212.47223, 210.46754, 212.47234,\n",
      "       198.72923, 201.68932, 207.05408, 202.95383, 212.14078, 210.76685,\n",
      "       198.98613, 199.2356 , 210.56462, 212.40846, 203.0937 , 204.32362,\n",
      "       220.97249, 196.85344], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 60, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23418, 201.37813, 212.4724 , 211.51895, 209.83743, 209.12091,\n",
      "       195.25763, 199.0297 , 197.63693, 196.99614, 195.51544, 210.02573,\n",
      "       199.19524, 199.51578, 212.45349, 211.49738, 212.0186 , 212.37804,\n",
      "       212.42613, 198.98595, 199.08751, 227.67416, 211.84503, 195.92891,\n",
      "       211.17671, 195.82283, 203.34499, 210.78276, 198.81624, 212.47229,\n",
      "       212.4722 , 200.89561, 207.40085, 212.47096, 210.44377, 212.4722 ,\n",
      "       198.54164, 196.18634, 199.58932, 200.02048, 210.93222, 206.21603,\n",
      "       198.99579, 198.99904, 210.10909, 212.09505, 200.07603, 202.22624,\n",
      "       215.7362 , 195.72672], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 70, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23337, 199.33405, 212.4723 , 208.41646, 207.03278, 203.74278,\n",
      "       195.2357 , 198.8761 , 196.9575 , 196.22464, 195.34602, 207.83939,\n",
      "       198.98053, 198.98706, 212.36531, 211.1132 , 210.24092, 211.9363 ,\n",
      "       212.20354, 198.98607, 198.9858 , 210.29187, 209.52252, 195.34006,\n",
      "       207.5444 , 195.28934, 199.95764, 210.58527, 198.75919, 212.47107,\n",
      "       212.47066, 199.22185, 199.83739, 212.46301, 210.3017 , 212.47061,\n",
      "       198.055  , 196.02213, 197.70287, 199.06398, 206.95924, 200.87329,\n",
      "       198.9964 , 198.98587, 207.83737, 210.50241, 199.0714 , 200.81209,\n",
      "       209.74629, 195.51653], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 80, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.2318 , 198.98593, 212.47166, 202.82115, 198.5998 , 197.35008,\n",
      "       195.23149, 198.8647 , 197.10606, 195.50438, 195.2704 , 199.57393,\n",
      "       198.9964 , 198.98553, 211.90184, 210.81255, 205.22397, 209.68462,\n",
      "       210.91138, 198.98593, 199.00162, 195.95401, 204.11037, 195.30936,\n",
      "       202.05684, 195.29564, 199.0153 , 209.89394, 198.5869 , 212.46309,\n",
      "       212.46033, 198.98781, 195.3226 , 212.40936, 209.34966, 212.45973,\n",
      "       197.44803, 195.31516, 196.76328, 198.99709, 201.61218, 198.96082,\n",
      "       198.98944, 198.99205, 199.97794, 205.6803 , 198.99574, 199.93282,\n",
      "       200.12045, 195.30754], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 90, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23126, 199.0352 , 212.46623, 199.4674 , 196.57726, 196.7086 ,\n",
      "       195.2314 , 198.74197, 197.06192, 195.2703 , 195.2421 , 197.57616,\n",
      "       198.99438, 198.9906 , 209.45793, 210.355  , 200.35672, 204.01048,\n",
      "       206.22606, 198.98593, 199.00012, 196.56786, 199.88478, 195.23264,\n",
      "       199.28622, 195.23157, 199.02768, 206.1152 , 198.17015, 212.40404,\n",
      "       212.38406, 199.03404, 195.76826, 212.02734, 203.62535, 212.37979,\n",
      "       196.86526, 195.33688, 195.78137, 199.02689, 199.19568, 198.91208,\n",
      "       198.98618, 198.98396, 195.5597 , 200.57631, 199.02684, 199.43307,\n",
      "       195.5374 , 195.26541], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 100, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23125, 199.02524, 212.42238, 198.99284, 195.81363, 195.67537,\n",
      "       195.23145, 198.43694, 196.90529, 195.23828, 195.23355, 196.36073,\n",
      "       198.96977, 198.95099, 201.33156, 207.94783, 198.99907, 199.70912,\n",
      "       200.66702, 198.98582, 198.99008, 196.57549, 198.98317, 195.2401 ,\n",
      "       199.01202, 195.23831, 199.0458 , 197.58386, 197.5763 , 211.94725,\n",
      "       211.80272, 199.0193 , 195.32047, 209.68199, 197.31502, 211.77173,\n",
      "       196.3291 , 195.23152, 195.34407, 199.00745, 199.02263, 198.88475,\n",
      "       198.986  , 198.96507, 195.75537, 199.0097 , 199.00674, 199.17583,\n",
      "       196.07718, 195.24298], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 110, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.2313 , 198.99461, 212.05003, 199.09705, 195.38751, 195.34367,\n",
      "       195.23146, 197.8422 , 196.69345, 195.24121, 195.23154, 195.48488,\n",
      "       198.92104, 198.88158, 196.60138, 198.93127, 199.09343, 198.99646,\n",
      "       198.99948, 198.9859 , 198.98463, 195.9481 , 199.09885, 195.23264,\n",
      "       199.09685, 195.23257, 199.0049 , 196.70807, 197.03171, 209.09161,\n",
      "       208.43694, 198.9925 , 195.27393, 203.41391, 196.65543, 208.3066 ,\n",
      "       195.92503, 195.2433 , 195.236  , 198.98917, 199.09215, 198.62283,\n",
      "       198.98602, 198.86574, 195.3889 , 199.08597, 198.98618, 199.05719,\n",
      "       195.35803, 195.23254], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 120, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.2313 , 198.98593, 209.43233, 199.03418, 195.2326 , 195.23239,\n",
      "       195.23134, 197.2757 , 196.47307, 195.23706, 195.23131, 195.24802,\n",
      "       198.63568, 198.61671, 196.35626, 196.11885, 199.07869, 199.13548,\n",
      "       199.12552, 198.98587, 198.9731 , 195.58975, 199.05731, 195.23271,\n",
      "       199.03107, 195.23213, 198.98668, 195.59845, 196.4701 , 202.4318 ,\n",
      "       201.78358, 198.98592, 195.25444, 199.33635, 195.51099, 201.66943,\n",
      "       195.64926, 195.2333 , 195.23424, 198.98592, 199.0243 , 198.12762,\n",
      "       198.98596, 198.3079 , 195.24823, 199.08157, 198.97298, 199.0088 ,\n",
      "       195.44525, 195.23346], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 130, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23126, 198.98666, 202.59332, 198.97688, 195.24998, 195.24028,\n",
      "       195.23126, 196.6065 , 196.31458, 195.23189, 195.23134, 195.2397 ,\n",
      "       198.06871, 198.00583, 195.6244 , 195.30075, 199.00034, 199.05408,\n",
      "       199.09315, 198.98587, 198.86307, 195.60872, 198.98737, 195.2315 ,\n",
      "       198.98811, 195.2315 , 198.98662, 195.36865, 196.0379 , 199.1028 ,\n",
      "       199.03355, 198.98657, 195.23149, 199.07785, 195.266  , 199.02449,\n",
      "       195.47461, 195.23242, 195.23723, 198.98645, 198.98692, 197.49979,\n",
      "       198.98589, 197.73213, 195.25847, 198.99663, 198.87262, 198.99191,\n",
      "       195.34254, 195.23134], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 140, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.2313 , 198.98651, 199.08443, 198.96037, 195.24019, 195.23901,\n",
      "       195.23123, 196.09642, 196.22075, 195.23138, 195.23134, 195.24298,\n",
      "       197.33087, 197.2834 , 195.3321 , 195.44029, 198.98618, 198.98906,\n",
      "       198.99796, 198.98587, 198.24626, 195.53876, 198.97244, 195.23132,\n",
      "       198.98749, 195.23131, 198.98691, 195.2387 , 195.73581, 199.15671,\n",
      "       199.17732, 198.9864 , 195.235  , 199.1707 , 195.2498 , 199.18047,\n",
      "       195.36864, 195.23178, 195.23434, 198.98619, 198.9866 , 196.72102,\n",
      "       198.98592, 197.04771, 195.23378, 198.97452, 198.26826, 198.98701,\n",
      "       195.34265, 195.23152], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 150, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23131, 198.98602, 199.19371, 198.88297, 195.23361, 195.23357,\n",
      "       195.23125, 195.74727, 196.13202, 195.23145, 195.23134, 195.23685,\n",
      "       196.63306, 196.59328, 195.2878 , 195.24258, 198.98914, 198.98866,\n",
      "       198.98732, 198.98587, 197.61484, 195.51028, 198.9374 , 195.23131,\n",
      "       198.98807, 195.23132, 198.98611, 195.24062, 195.53777, 199.15239,\n",
      "       199.13162, 198.986  , 195.2317 , 199.02423, 195.24448, 199.12775,\n",
      "       195.3066 , 195.23126, 195.23189, 198.98586, 198.9781 , 196.1044 ,\n",
      "       198.98586, 196.46777, 195.2342 , 198.95609, 197.58713, 198.986  ,\n",
      "       195.3212 , 195.23132], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 160, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23134, 198.98592, 199.15683, 198.28009, 195.2319 , 195.23167,\n",
      "       195.23128, 195.52753, 196.04147, 195.23134, 195.23126, 195.23222,\n",
      "       196.11575, 196.0595 , 195.24135, 195.24295, 198.98703, 198.98915,\n",
      "       198.99028, 198.98586, 196.90616, 195.48376, 198.55928, 195.23128,\n",
      "       198.98627, 195.23131, 198.98587, 195.24092, 195.4126 , 199.00275,\n",
      "       198.99664, 198.98584, 195.23143, 198.9862 , 195.23761, 198.99568,\n",
      "       195.2713 , 195.23137, 195.23128, 198.9859 , 198.86646, 195.7044 ,\n",
      "       198.98587, 196.01826, 195.23232, 198.74362, 196.83638, 198.98595,\n",
      "       195.31168, 195.23132], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 170, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23128, 198.9859 , 198.99738, 197.47844, 195.23146, 195.23141,\n",
      "       195.23128, 195.39687, 195.95845, 195.23134, 195.23132, 195.2313 ,\n",
      "       195.76413, 195.72066, 195.23125, 195.24078, 198.98586, 198.98625,\n",
      "       198.98683, 198.98587, 196.30151, 195.45811, 197.79364, 195.23128,\n",
      "       198.98589, 195.2313 , 198.98587, 195.23335, 195.33627, 198.98958,\n",
      "       198.99065, 198.98593, 195.23146, 198.99269, 195.23254, 198.99075,\n",
      "       195.2519 , 195.23128, 195.23128, 198.98586, 198.15755, 195.47217,\n",
      "       198.98589, 195.72005, 195.23126, 198.03587, 196.20984, 198.98589,\n",
      "       195.30154, 195.23126], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 180, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.2313 , 198.9859 , 198.99236, 196.6472 , 195.23141, 195.23132,\n",
      "       195.2313 , 195.32126, 195.881  , 195.23128, 195.23126, 195.23138,\n",
      "       195.54372, 195.50755, 195.23256, 195.2317 , 198.98602, 198.9859 ,\n",
      "       198.98584, 198.98587, 195.88263, 195.43596, 196.84836, 195.23125,\n",
      "       198.98589, 195.23123, 198.9859 , 195.23155, 195.29077, 198.9931 ,\n",
      "       198.99239, 198.98589, 195.23134, 198.98691, 195.23135, 198.99217,\n",
      "       195.2416 , 195.23125, 195.23132, 198.98587, 197.37192, 195.3467 ,\n",
      "       198.98586, 195.52586, 195.23146, 197.09892, 195.79858, 198.98593,\n",
      "       195.29283, 195.23125], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 190, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23128, 198.98582, 198.99345, 195.99469, 195.23128, 195.2313 ,\n",
      "       195.23126, 195.27888, 195.80872, 195.2313 , 195.23126, 195.23143,\n",
      "       195.40935, 195.38309, 195.23221, 195.2318 , 198.98593, 198.98602,\n",
      "       198.98608, 198.9859 , 195.61108, 195.41483, 196.15482, 195.2313 ,\n",
      "       198.98592, 195.2313 , 198.98582, 195.23145, 195.26425, 198.98654,\n",
      "       198.98651, 198.98589, 195.23126, 198.96823, 195.23148, 198.98595,\n",
      "       195.23625, 195.23128, 195.23128, 198.98586, 196.53354, 195.2844 ,\n",
      "       198.98592, 195.4052 , 195.23135, 196.28539, 195.54361, 198.98592,\n",
      "       195.28514, 195.23126], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 200, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23131, 198.98587, 198.98636, 195.6189 , 195.23132, 195.2313 ,\n",
      "       195.23126, 195.25586, 195.74213, 195.2313 , 195.23125, 195.23132,\n",
      "       195.33049, 195.31271, 195.23155, 195.23169, 198.98589, 198.98586,\n",
      "       198.98595, 198.98586, 195.44737, 195.39552, 195.69768, 195.23125,\n",
      "       198.98587, 195.23125, 198.98589, 195.23138, 195.24915, 198.98233,\n",
      "       198.98605, 198.98589, 195.23125, 198.7382 , 195.23135, 198.97781,\n",
      "       195.2336 , 195.2313 , 195.23126, 198.98584, 195.91972, 195.25461,\n",
      "       198.98586, 195.33206, 195.23125, 195.77698, 195.39777, 198.98589,\n",
      "       195.27815, 195.23125], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 210, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23131, 198.98592, 198.9862 , 195.41461, 195.23128, 195.23128,\n",
      "       195.2313 , 195.2436 , 195.68108, 195.23126, 195.23132, 195.23128,\n",
      "       195.28545, 195.27393, 195.23134, 195.23134, 198.98587, 198.98587,\n",
      "       198.9859 , 198.9859 , 195.35153, 195.37767, 195.4516 , 195.23126,\n",
      "       198.98595, 195.23126, 198.98589, 195.2313 , 195.24072, 198.92635,\n",
      "       198.98618, 198.98587, 195.2313 , 197.98041, 195.23126, 198.85794,\n",
      "       195.23233, 195.23128, 195.2313 , 198.98593, 195.56805, 195.24098,\n",
      "       198.98589, 195.28864, 195.23123, 195.4923 , 195.31764, 198.98593,\n",
      "       195.27197, 195.23126], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 220, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23126, 198.98589, 198.98619, 195.3131 , 195.23131, 195.2313 ,\n",
      "       195.23126, 195.2373 , 195.62546, 195.23128, 195.2313 , 195.23131,\n",
      "       195.26022, 195.25305, 195.23126, 195.2313 , 198.98589, 198.98589,\n",
      "       198.98589, 198.98586, 195.29683, 195.36127, 195.32979, 195.23128,\n",
      "       198.98587, 195.23126, 198.98592, 195.2313 , 195.23611, 198.32106,\n",
      "       198.9859 , 198.98587, 195.23126, 196.91649, 195.2313 , 198.0784 ,\n",
      "       195.23177, 195.23125, 195.23123, 198.98587, 195.3866 , 195.2351 ,\n",
      "       198.98586, 195.26335, 195.23128, 195.34776, 195.27489, 198.98581,\n",
      "       195.26643, 195.23132], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 230, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.23128, 198.9859 , 198.9859 , 195.26596, 195.2313 , 195.23125,\n",
      "       195.2313 , 195.2341 , 195.5751 , 195.23125, 195.23123, 195.23126,\n",
      "       195.24638, 195.24214, 195.23131, 195.23134, 198.98589, 198.98592,\n",
      "       198.98592, 198.9859 , 195.26633, 195.3463 , 195.27307, 195.23122,\n",
      "       198.98586, 195.2313 , 198.9859 , 195.23125, 195.23367, 197.40097,\n",
      "       198.98589, 198.98587, 195.23123, 196.103  , 195.23131, 197.16693,\n",
      "       195.23148, 195.23128, 195.2313 , 198.98582, 195.29892, 195.23274,\n",
      "       198.98586, 195.24892, 195.23128, 195.28026, 195.25276, 198.98587,\n",
      "       195.26155, 195.23125], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 240, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([195.2313 , 198.98593, 198.98589, 195.24521, 195.23123, 195.23123,\n",
      "       195.23126, 195.23257, 195.52982, 195.23126, 195.2313 , 195.2313 ,\n",
      "       195.239  , 195.23656, 195.23128, 195.23131, 198.98587, 198.98586,\n",
      "       198.98589, 198.98589, 195.24962, 195.33276, 195.2481 , 195.2312 ,\n",
      "       198.98584, 195.23125, 198.98592, 195.23125, 195.23247, 196.45885,\n",
      "       198.98592, 198.9859 , 195.23128, 195.61482, 195.2313 , 196.21466,\n",
      "       195.2313 , 195.23123, 195.2313 , 198.98584, 195.25919, 195.23177,\n",
      "       198.98587, 195.2408 , 195.2313 , 195.2507 , 195.24153, 198.98584,\n",
      "       195.25726, 195.23128], dtype=float32)\n",
      "  batch_dim = 0\n",
      "     -> Agent : ck\n",
      "step 0, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 212.47246,  210.69275,  212.44882,  212.47237,  212.46773,\n",
      "        212.47246,  394.34802,  212.47237,  208.4584 ,  212.47173,\n",
      "        488.05984,  513.93353,  666.7075 ,  212.46317,  212.47246,\n",
      "        211.86726, 1111.4725 ,  201.47078,  462.98178,  212.45189,\n",
      "        975.591  ,  203.5821 ,  212.47237,  202.56647,  212.47246,\n",
      "        212.4724 ,  209.42018,  273.1505 ,  212.47073,  813.1864 ,\n",
      "        212.47243,  652.8714 ,  999.4359 ,  619.05334,  199.01701,\n",
      "        212.47237,  395.82272,  211.3504 ,  203.83261,  202.4398 ,\n",
      "        212.47243,  212.47246,  212.47246,  753.38794,  399.63596,\n",
      "        212.47194,  228.87186,  210.47655,  205.76695,  211.93307],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 10, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 212.47246,  210.54657,  212.41058,  212.47237,  212.45917,\n",
      "        212.47246,  308.01703,  212.47232,  204.90738,  212.46997,\n",
      "        406.13217,  450.9025 ,  597.5005 ,  212.44734,  212.47246,\n",
      "        210.5105 , 1051.1571 ,  189.59062,  348.75198,  212.41817,\n",
      "        915.3669 ,  196.27914,  212.47234,  194.01329,  212.47246,\n",
      "        212.47237,  204.28374,  215.43297,  212.46733,  752.2378 ,\n",
      "        212.47237,  592.88824,  939.19403,  559.1127 ,  186.8801 ,\n",
      "        212.47232,  337.93918,  211.10083,  195.74413,  194.08046,\n",
      "        212.47238,  212.47246,  212.47238,  693.27496,  341.63055,\n",
      "        212.47159,  199.39552,  210.47295,  194.74161,  211.61186],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 20, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.47246, 210.3683 , 212.3119 , 212.47232, 212.43265, 212.47246,\n",
      "       222.27728, 212.4718 , 199.17673, 212.46497, 304.61862, 383.21936,\n",
      "       513.66376, 212.40161, 212.47246, 206.69711, 990.8855 , 189.64354,\n",
      "       300.9036 , 212.32935, 855.1884 , 193.7732 , 212.47217, 188.41603,\n",
      "       212.47246, 212.47232, 194.84805, 198.9364 , 212.4568 , 689.78986,\n",
      "       212.47218, 533.00354, 879.0004 , 499.3102 , 177.89076, 212.47186,\n",
      "       283.61926, 210.8862 , 189.38528, 189.18088, 212.47223, 212.47246,\n",
      "       212.47226, 633.145  , 286.98944, 212.46931, 189.73941, 210.47166,\n",
      "       181.01337, 211.33534], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 30, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.47246, 209.9229 , 212.09169, 212.4718 , 212.33606, 212.4724 ,\n",
      "       183.3084 , 212.47096, 199.14514, 212.44594, 212.40398, 303.823  ,\n",
      "       393.67157, 212.27191, 212.47246, 197.68594, 930.6599 , 189.50607,\n",
      "       276.98383, 212.12064, 795.06335, 189.71422, 212.47173, 183.41397,\n",
      "       212.47246, 212.47217, 185.86172, 199.4246 , 212.41876, 621.993  ,\n",
      "       212.47153, 473.32166, 818.8577 , 439.8234 , 178.37025, 212.4711 ,\n",
      "       237.85867, 210.67955, 189.92947, 189.83607, 212.47171, 212.47246,\n",
      "       212.47194, 572.8326 , 240.5079 , 212.46208, 189.3696 , 210.46902,\n",
      "       179.19395, 211.10228], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 40, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.47246, 208.14117, 211.74568, 212.47055, 211.9329 , 212.47237,\n",
      "       177.91843, 212.4653 , 198.76013, 212.36694, 183.91753, 216.02129,\n",
      "       249.98831, 211.98328, 212.47246, 187.09973, 870.4624 , 189.17603,\n",
      "       251.56296, 211.76143, 734.9966 , 183.82314, 212.46887, 178.70522,\n",
      "       212.47246, 212.47154, 179.75545, 199.68092, 212.25836, 534.33044,\n",
      "       212.46878, 414.1183 , 758.7681 , 381.1263 , 176.92972, 212.46585,\n",
      "       207.36664, 210.35336, 189.19809, 189.17763, 212.46939, 212.47246,\n",
      "       212.46957, 511.6093 , 208.91414, 212.42987, 189.62852, 210.45834,\n",
      "       176.99109, 210.89688], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 50, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.47244, 201.19733, 211.37479, 212.4628 , 210.09808, 212.47226,\n",
      "       178.11852, 212.43991, 198.32271, 211.9911 , 180.35728, 179.68433,\n",
      "       198.55548, 211.56087, 212.47237, 180.94084, 810.1926 , 189.21938,\n",
      "       220.21977, 211.25581, 674.992  , 178.57834, 212.45584, 176.88678,\n",
      "       212.47246, 212.4673 , 177.45131, 199.27074, 211.50282, 386.31564,\n",
      "       212.45573, 356.12378, 698.71893, 324.45004, 177.00142, 212.44205,\n",
      "       193.54016, 209.3012 , 189.28125, 189.26407, 212.45831, 212.47246,\n",
      "       212.4587 , 446.12177, 194.1803 , 212.27756, 189.35619, 210.40692,\n",
      "       177.08333, 210.6445 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 60, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.4724 , 199.20119, 211.0499 , 212.42195, 202.48303, 212.47159,\n",
      "       178.12196, 212.30196, 198.0894 , 210.05856, 180.14465, 178.3716 ,\n",
      "       189.39107, 211.00389, 212.47232, 177.67415, 749.29865, 189.14575,\n",
      "       201.43692, 210.03908, 615.0629 , 176.86111, 212.38544, 177.04506,\n",
      "       212.47246, 212.44469, 176.94107, 198.82112, 207.83435, 230.64235,\n",
      "       212.39153, 301.16214, 638.63495, 272.66644, 176.88411, 212.31346,\n",
      "       189.49292, 204.66132, 189.17805, 189.1754 , 212.39125, 212.47246,\n",
      "       212.39915, 361.79904, 189.89061, 211.46646, 189.12465, 210.12042,\n",
      "       176.88559, 209.95743], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 70, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.47214, 198.05026, 210.67892, 212.17377, 189.41557, 212.46634,\n",
      "       177.76535, 211.48169, 197.85757, 201.39839, 179.92192, 178.96715,\n",
      "       187.47118, 209.35527, 212.47159, 176.89832, 684.5418 , 189.0003 ,\n",
      "       198.28972, 204.1278 , 555.23474, 177.13762, 211.96135, 176.96443,\n",
      "       212.47246, 212.30798, 176.94284, 198.64911, 195.25452, 197.46315,\n",
      "       212.1308 , 253.10997, 578.0431 , 230.8833 , 176.86578, 211.54639,\n",
      "       188.01006, 199.37617, 189.19179, 189.16585, 211.86298, 212.47246,\n",
      "       212.03993, 235.179  , 189.19586, 207.13818, 188.80145, 208.26625,\n",
      "       176.88393, 206.7103 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 80, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.47028, 197.43953, 209.40656, 210.57062, 190.52458, 212.43256,\n",
      "       177.41078, 206.68163, 197.59134, 189.19524, 179.50308, 178.42891,\n",
      "       186.71921, 200.89522, 212.46555, 176.95029, 596.4829 , 188.01346,\n",
      "       198.34755, 195.46211, 495.58264, 176.93694, 209.30547, 176.85756,\n",
      "       212.47246, 211.40799, 176.89882, 198.62892, 190.84348, 192.47414,\n",
      "       211.48944, 217.4106 , 513.9197 , 203.3657 , 176.86401, 207.01834,\n",
      "       185.07008, 198.09877, 189.17772, 189.05075, 207.16202, 212.47246,\n",
      "       209.76466, 183.07494, 189.20016, 192.93407, 186.99767, 199.39987,\n",
      "       176.87006, 198.31395], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 90, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.4569 , 197.16112, 201.86435, 201.68901, 189.42407, 212.18265,\n",
      "       177.20184, 191.44017, 197.2893 , 189.92195, 179.03752, 177.68822,\n",
      "       186.1519 , 196.67783, 212.42215, 176.91089, 402.8496 , 183.4012 ,\n",
      "       198.42358, 191.15776, 436.30673, 176.85829, 197.0445 , 176.86658,\n",
      "       212.47246, 205.75691, 176.86195, 198.59337, 189.1904 , 191.22797,\n",
      "       209.43077, 195.36647, 427.4194 , 186.45741, 176.85692, 191.92336,\n",
      "       184.05504, 197.63515, 189.17828, 188.26797, 188.62468, 212.47246,\n",
      "       198.54819, 182.25026, 189.22473, 191.41115, 182.49872, 198.3204 ,\n",
      "       176.85652, 198.04997], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 100, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.33936, 196.8152 , 198.21072, 189.50108, 189.23306, 210.25331,\n",
      "       177.09767, 191.28294, 196.90059, 189.57906, 178.61981, 177.29431,\n",
      "       185.59724, 191.89174, 212.07169, 176.86716, 224.74007, 178.76541,\n",
      "       198.35635, 182.58679, 377.93933, 176.87138, 191.15334, 176.85999,\n",
      "       212.47246, 189.91902, 176.8571 , 198.5511 , 189.50204, 190.56583,\n",
      "       198.3591 , 181.3386 , 261.1702 , 181.03058, 176.85631, 191.39037,\n",
      "       182.23671, 197.38344, 189.17752, 183.83351, 182.20808, 212.47246,\n",
      "       190.63474, 182.7354 , 189.21158, 189.25519, 179.60716, 198.30641,\n",
      "       176.85655, 197.83247], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 110, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([211.10135, 196.23062, 196.04999, 189.46434, 189.2341 , 198.79799,\n",
      "       177.03056, 189.44598, 196.29977, 189.17389, 178.27216, 177.179  ,\n",
      "       185.02682, 184.09499, 209.2072 , 176.86116, 202.15137, 176.99133,\n",
      "       198.26422, 176.96727, 321.83533, 176.85736, 189.17854, 176.85603,\n",
      "       212.4724 , 190.63286, 176.85799, 198.51569, 189.2057 , 190.00082,\n",
      "       192.96304, 182.13112, 188.94165, 181.27782, 176.8563 , 189.41101,\n",
      "       180.67125, 197.05768, 189.17702, 178.37535, 177.18613, 212.47246,\n",
      "       188.97783, 182.06908, 189.19194, 189.36804, 177.7398 , 197.89648,\n",
      "       176.85667, 197.55652], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 120, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([199.59206, 195.07762, 194.12535, 189.66702, 189.0771 , 191.33817,\n",
      "       176.97667, 189.2539 , 195.053  , 189.17453, 177.98262, 177.11998,\n",
      "       184.43849, 177.21921, 194.33871, 176.85934, 198.43143, 176.9653 ,\n",
      "       198.20409, 177.51027, 271.06342, 176.85683, 189.49231, 176.85661,\n",
      "       212.472  , 189.65128, 176.85672, 198.47939, 189.1452 , 189.43799,\n",
      "       183.04741, 180.42468, 186.89818, 180.33786, 176.85603, 189.26674,\n",
      "       179.46877, 196.56616, 189.17726, 176.99767, 177.08015, 212.47246,\n",
      "       188.01112, 181.02702, 189.18105, 189.25964, 177.0296 , 197.52562,\n",
      "       176.8561 , 197.23227], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 130, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([183.88661, 191.49179, 188.0856 , 189.18263, 188.17159, 189.2007 ,\n",
      "       176.9361 , 189.25114, 190.91078, 188.68398, 177.73709, 177.05623,\n",
      "       183.83513, 177.53891, 191.86212, 176.85667, 196.90276, 176.94958,\n",
      "       198.17592, 176.98328, 230.88918, 176.85657, 189.2336 , 176.85597,\n",
      "       212.46028, 189.18292, 176.85599, 198.44138, 188.79596, 188.85832,\n",
      "       176.9142 , 180.07568, 187.32295, 179.59497, 176.85597, 189.18336,\n",
      "       178.58017, 195.73102, 189.17726, 177.08862, 177.08293, 212.47246,\n",
      "       180.266  , 180.14331, 189.17757, 189.17741, 176.86874, 197.1301 ,\n",
      "       176.85596, 196.80254], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 140, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([177.89993, 182.78447, 178.97498, 188.98018, 182.25017, 189.46803,\n",
      "       176.90796, 188.99068, 181.76231, 184.77362, 177.52946, 177.00429,\n",
      "       183.22069, 177.04443, 189.5521 , 176.85611, 196.09793, 176.87842,\n",
      "       198.16222, 176.89053, 205.87204, 176.85593, 188.92104, 176.85596,\n",
      "       212.27844, 189.24442, 176.85597, 198.4024 , 185.50385, 188.2596 ,\n",
      "       177.63608, 179.27242, 186.88892, 179.00877, 176.85593, 188.34015,\n",
      "       177.96297, 193.54132, 189.17723, 176.93292, 176.90079, 212.47244,\n",
      "       177.08026, 179.58421, 189.17728, 189.18567, 176.85803, 196.61884,\n",
      "       176.85596, 196.15771], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 150, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([177.32907, 176.89099, 177.29097, 187.11316, 177.22125, 189.30179,\n",
      "       176.88895, 187.08316, 176.90889, 178.42802, 177.35847, 176.96648,\n",
      "       182.60042, 176.89009, 189.2269 , 176.85602, 195.60791, 176.8574 ,\n",
      "       198.15118, 176.88737, 194.45453, 176.85606, 186.65146, 176.85596,\n",
      "       210.24591, 189.19972, 176.85599, 198.36224, 179.03514, 187.6438 ,\n",
      "       176.93724, 178.73521, 186.0516 , 178.462  , 176.85593, 182.84752,\n",
      "       177.55237, 186.16098, 189.1772 , 176.85805, 176.87595, 212.47224,\n",
      "       177.20386, 179.22847, 189.17715, 189.18121, 176.86224, 195.70108,\n",
      "       176.85599, 194.7439 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 160, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([177.25264, 177.64728, 177.36209, 180.02402, 177.05576, 189.1811 ,\n",
      "       176.87631, 179.91823, 177.6283 , 176.9507 , 177.22195, 176.93726,\n",
      "       181.98083, 176.89372, 189.20776, 176.85597, 195.27725, 176.85913,\n",
      "       198.13948, 176.85649, 190.54474, 176.85593, 179.63632, 176.85596,\n",
      "       195.40479, 189.17722, 176.85591, 198.32095, 177.03871, 187.01357,\n",
      "       176.91692, 178.2837 , 185.17697, 178.05745, 176.85593, 177.24486,\n",
      "       177.28683, 177.64702, 189.17728, 176.86568, 176.86073, 212.4699 ,\n",
      "       177.03201, 178.92383, 189.17725, 189.17723, 176.86073, 192.994  ,\n",
      "       176.85591, 189.63445], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 170, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.91841, 176.94261, 176.86118, 177.15028, 177.11977, 189.18382,\n",
      "       176.86816, 177.1818 , 176.88986, 177.12639, 177.11635, 176.91452,\n",
      "       181.36949, 176.8565 , 188.34398, 176.85593, 195.03726, 176.85777,\n",
      "       198.1271 , 176.86041, 189.46733, 176.85593, 177.09848, 176.85585,\n",
      "       190.89323, 189.17894, 176.85591, 198.27861, 177.12976, 186.37137,\n",
      "       176.88094, 177.91905, 184.39998, 177.74446, 176.85594, 177.12299,\n",
      "       177.11897, 177.61595, 189.17711, 176.86061, 176.85608, 212.43948,\n",
      "       176.86948, 178.62906, 189.1773 , 189.17741, 176.85791, 184.47144,\n",
      "       176.85593, 179.97899], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 180, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.8947 , 176.91837, 176.92653, 177.19044, 176.90532, 189.18367,\n",
      "       176.86305, 177.2163 , 176.93416, 176.94215, 177.03696, 176.89749,\n",
      "       180.77509, 176.86105, 181.99695, 176.85591, 194.85072, 176.85612,\n",
      "       198.1145 , 176.85597, 189.22258, 176.85591, 177.16905, 176.85593,\n",
      "       184.62068, 189.17851, 176.85594, 198.23502, 176.94585, 185.71925,\n",
      "       176.85919, 177.64398, 183.74129, 177.5052 , 176.85594, 177.15106,\n",
      "       177.01479, 177.15038, 189.17714, 176.85617, 176.85684, 212.11739,\n",
      "       176.86766, 178.35638, 189.17715, 189.17746, 176.85638, 176.98276,\n",
      "       176.85594, 177.21602], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 190, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.86398, 176.87997, 176.85661, 176.99113, 176.86253, 189.17838,\n",
      "       176.85997, 176.98456, 176.86774, 176.86534, 176.9788 , 176.88495,\n",
      "       180.2065 , 176.85599, 177.08855, 176.85591, 194.69383, 176.85593,\n",
      "       198.10162, 176.85648, 189.18034, 176.85591, 176.97284, 176.8559 ,\n",
      "       177.87459, 189.17743, 176.85599, 198.19041, 176.86409, 185.05887,\n",
      "       176.8601 , 177.43608, 183.17433, 177.32715, 176.85596, 176.89436,\n",
      "       176.95085, 176.89075, 189.17723, 176.85634, 176.8561 , 209.66565,\n",
      "       176.8643 , 178.11188, 189.177  , 189.1773 , 176.85602, 177.79721,\n",
      "       176.85596, 177.48514], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 200, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.85732, 176.85976, 176.86429, 176.86633, 176.8654 , 189.17703,\n",
      "       176.85814, 176.86032, 176.8631 , 176.86864, 176.9375 , 176.87587,\n",
      "       179.67253, 176.85652, 177.29028, 176.85591, 194.54994, 176.856  ,\n",
      "       198.08833, 176.85602, 189.17734, 176.85593, 176.86636, 176.85596,\n",
      "       177.16174, 189.17699, 176.85594, 198.14458, 176.87086, 184.39272,\n",
      "       176.85608, 177.27992, 182.65657, 177.19582, 176.85599, 176.86118,\n",
      "       176.91197, 176.90692, 189.17714, 176.85608, 176.85605, 193.13272,\n",
      "       176.8564 , 177.89453, 189.17719, 189.17725, 176.856  , 176.95851,\n",
      "       176.85594, 176.86098], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 210, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.85715, 176.85991, 176.85625, 176.87257, 176.8574 , 189.17719,\n",
      "       176.85712, 176.87279, 176.85825, 176.8586 , 176.90883, 176.86938,\n",
      "       179.18103, 176.85602, 177.08478, 176.85594, 194.40704, 176.85596,\n",
      "       198.07466, 176.85603, 189.1781 , 176.85591, 176.8722 , 176.85591,\n",
      "       177.24098, 189.17711, 176.85596, 198.09756, 176.85985, 183.72365,\n",
      "       176.85652, 177.16388, 182.15657, 177.09964, 176.85591, 176.86816,\n",
      "       176.88864, 176.85728, 189.17726, 176.85596, 176.85599, 184.23093,\n",
      "       176.85655, 177.70355, 189.17725, 189.17708, 176.85597, 176.94406,\n",
      "       176.85591, 176.93848], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 220, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.85591, 176.8562 , 176.8569 , 176.8615 , 176.85654, 189.17737,\n",
      "       176.85655, 176.86232, 176.85661, 176.85631, 176.88954, 176.86488,\n",
      "       178.73859, 176.85599, 176.86491, 176.85591, 194.25586, 176.85596,\n",
      "       198.06058, 176.85594, 189.1783 , 176.85597, 176.8603 , 176.85594,\n",
      "       176.90707, 189.17703, 176.85591, 198.04924, 176.85603, 183.05588,\n",
      "       176.85594, 177.07828, 181.6639 , 177.02954, 176.85594, 176.85767,\n",
      "       176.87473, 176.86287, 189.17703, 176.85596, 176.85594, 177.18199,\n",
      "       176.85631, 177.5386 , 189.17711, 189.17719, 176.85593, 176.87764,\n",
      "       176.85593, 176.85654], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 230, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.8561 , 176.85652, 176.85599, 176.85612, 176.8564 , 189.17708,\n",
      "       176.85626, 176.856  , 176.8563 , 176.85663, 176.87679, 176.86179,\n",
      "       178.3497 , 176.85594, 176.8749 , 176.85594, 194.08838, 176.85593,\n",
      "       198.04619, 176.85594, 189.17795, 176.85594, 176.85619, 176.85591,\n",
      "       176.866  , 189.17708, 176.85593, 197.99966, 176.85663, 182.39487,\n",
      "       176.856  , 177.01567, 181.18079, 176.97891, 176.85594, 176.85637,\n",
      "       176.86658, 176.856  , 189.1772 , 176.85596, 176.85591, 177.85583,\n",
      "       176.85593, 177.39859, 189.17699, 189.177  , 176.85596, 176.86415,\n",
      "       176.85594, 176.86601], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 240, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([176.85593, 176.85594, 176.85603, 176.85681, 176.85596, 189.17697,\n",
      "       176.85611, 176.85672, 176.85599, 176.85603, 176.8686 , 176.85973,\n",
      "       178.01651, 176.85596, 176.86598, 176.85594, 193.89711, 176.85594,\n",
      "       198.03133, 176.85593, 189.17747, 176.85594, 176.85683, 176.85596,\n",
      "       176.87366, 189.17703, 176.85593, 197.94849, 176.85612, 181.74713,\n",
      "       176.85596, 176.97   , 180.71242, 176.9425 , 176.85593, 176.85645,\n",
      "       176.86197, 176.85686, 189.17703, 176.8559 , 176.85597, 176.90787,\n",
      "       176.85599, 177.28159, 189.17703, 189.1772 , 176.85594, 176.8593 ,\n",
      "       176.85596, 176.85612], dtype=float32)\n",
      "  batch_dim = 0\n",
      "     -> Agent : rw_ck\n",
      "step 0, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.63712, 214.42967, 214.62859, 214.68616, 213.60953, 214.63713,\n",
      "       214.63713, 474.8229 , 214.63713, 214.57092, 215.87518, 212.30484,\n",
      "       269.38626, 214.63713, 419.79733, 214.24356, 706.0535 , 214.5236 ,\n",
      "       203.85011, 214.60909, 214.63713, 186.67726, 259.92288, 222.22957,\n",
      "       214.97372, 210.08957, 214.5228 , 806.7969 , 894.4905 , 480.09695,\n",
      "       706.6504 , 213.97205, 214.633  , 214.8626 , 212.94148, 214.51244,\n",
      "       190.88824, 214.63664, 191.79195, 214.63698, 206.12766, 394.50308,\n",
      "       307.8988 , 214.59218, 566.7806 , 208.41345, 212.45801, 214.6115 ,\n",
      "       214.63713, 202.36229], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 10, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.63712, 214.05943, 214.53825, 214.61034, 209.6164 , 214.63713,\n",
      "       214.63713, 325.14468, 214.63713, 214.53334, 215.63835, 207.2217 ,\n",
      "       224.07002, 214.63713, 320.05508, 213.52019, 645.802  , 214.51291,\n",
      "       202.61226, 214.52472, 214.63701, 182.26265, 250.58353, 216.8938 ,\n",
      "       214.88261, 207.30214, 214.51326, 746.0689 , 714.1516 , 420.5619 ,\n",
      "       521.6056 , 212.54141, 214.62645, 214.7556 , 209.89334, 214.51201,\n",
      "       189.40942, 214.63513, 182.04007, 214.63672, 203.92616, 336.62317,\n",
      "       219.82133, 214.5653 , 506.85123, 198.05884, 209.07814, 214.58846,\n",
      "       214.63713, 199.34341], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 20, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.63712, 212.94173, 214.45027, 214.50931, 206.49411, 214.63707,\n",
      "       214.63713, 256.54797, 214.63713, 214.49103, 215.4176 , 197.1065 ,\n",
      "       196.24405, 214.63704, 225.76079, 211.89638, 585.22095, 214.50963,\n",
      "       202.3342 , 214.19397, 214.63684, 180.0394 , 239.27638, 212.14359,\n",
      "       214.80217, 204.73755, 214.51195, 684.89716, 488.03546, 361.97116,\n",
      "       341.91324, 208.04776, 214.61118, 214.66982, 203.09117, 214.51195,\n",
      "       185.84444, 214.63068, 181.42928, 214.63593, 202.621  , 282.5641 ,\n",
      "       192.1947 , 214.54042, 447.1455 , 183.60889, 201.7426 , 214.56053,\n",
      "       214.63696, 192.34329], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 30, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.63708, 209.36905, 214.29745, 214.28815, 204.21736, 214.63704,\n",
      "       214.63713, 224.91507, 214.63713, 214.39775, 215.19559, 188.11081,\n",
      "       185.15343, 214.637  , 187.84485, 208.92691, 523.4835 , 214.5037 ,\n",
      "       202.37465, 212.95941, 214.63503, 180.1006 , 223.24533, 207.63222,\n",
      "       214.73097, 202.89418, 214.51123, 622.5183 , 339.87375, 305.9601 ,\n",
      "       266.1767 , 199.18079, 214.58064, 214.60098, 200.85754, 214.51205,\n",
      "       180.68498, 214.61505, 180.07837, 214.63303, 201.6625 , 237.6018 ,\n",
      "       185.9992 , 214.5231 , 388.0493 , 181.7498 , 190.21248, 214.53539,\n",
      "       214.637  , 179.4897 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 40, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.63689, 199.92664, 213.72005, 213.50214, 202.2548 , 214.63695,\n",
      "       214.63704, 209.9892 , 214.63713, 214.04602, 214.88928, 184.16615,\n",
      "       181.64389, 214.63681, 178.98329, 205.50066, 457.24493, 214.4759 ,\n",
      "       202.33705, 208.49998, 214.62288, 180.05774, 204.74295, 201.24428,\n",
      "       214.65996, 201.22327, 214.50691, 560.1511 , 273.73184, 256.1883 ,\n",
      "       237.24431, 194.89568, 214.53415, 214.53943, 199.3863 , 214.51137,\n",
      "       180.16258, 214.54895, 179.95134, 214.62297, 198.3995 , 208.41327,\n",
      "       184.53525, 214.5128 , 330.53314, 180.06818, 183.0903 , 214.51643,\n",
      "       214.63594, 176.29866], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 50, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.63611, 191.45625, 211.02298, 210.04622, 198.50458, 214.6364 ,\n",
      "       214.63698, 200.70634, 214.63713, 212.44382, 214.09647, 180.56378,\n",
      "       180.4934 , 214.63553, 176.11552, 203.2423 , 373.50964, 214.33833,\n",
      "       202.29434, 196.84964, 214.54132, 179.9505 , 195.96466, 188.58174,\n",
      "       214.54475, 197.16373, 214.48668, 499.8836 , 246.16513, 218.20601,\n",
      "       224.38364, 188.12486, 214.4421 , 214.45766, 198.05295, 214.50815,\n",
      "       179.45326, 214.23407, 179.7377 , 214.59093, 187.31908, 195.66396,\n",
      "       183.34312, 214.50046, 276.67786, 180.20802, 177.21445, 214.49057,\n",
      "       214.63013, 174.55045], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 60, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.62753, 190.65771, 203.15834, 202.28822, 188.45784, 214.63254,\n",
      "       214.63646, 194.52438, 214.63712, 205.46272, 210.7819 , 179.93013,\n",
      "       179.47954, 214.62837, 175.49117, 202.42094, 250.69444, 213.52126,\n",
      "       202.0953 , 189.0614 , 214.076  , 179.9564 , 193.77798, 187.97726,\n",
      "       214.15004, 188.61617, 214.36621, 439.36432, 231.40263, 194.37166,\n",
      "       217.17493, 181.86559, 214.06262, 214.19592, 194.31424, 214.49026,\n",
      "       177.56271, 212.6018 , 179.11234, 214.51054, 181.80185, 192.01797,\n",
      "       180.65616, 214.44511, 229.46188, 179.96399, 175.13203, 214.37468,\n",
      "       214.59633, 174.33305], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 70, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([214.48686, 186.1109 , 194.75972, 198.51913, 176.87616, 214.60811,\n",
      "       214.63318, 190.35414, 214.63712, 190.51045, 202.01753, 179.9719 ,\n",
      "       177.7993 , 214.58511, 175.43652, 202.2443 , 188.34167, 208.6266 ,\n",
      "       200.61441, 182.32918, 211.4666 , 179.91592, 191.6724 , 187.2522 ,\n",
      "       212.05502, 188.16809, 213.46802, 376.25467, 220.47229, 183.28308,\n",
      "       212.09451, 179.83467, 211.8269 , 212.61928, 187.15807, 214.36755,\n",
      "       175.05199, 204.97278, 177.85   , 214.14645, 177.74866, 190.29396,\n",
      "       176.80638, 214.07123, 192.0345 , 179.984  , 174.27425, 213.56255,\n",
      "       214.39532, 174.31035], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 80, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([212.22784, 181.6684 , 189.90361, 192.13138, 174.43567, 214.44647,\n",
      "       214.60458, 187.72069, 214.63708, 187.76854, 198.53491, 179.87714,\n",
      "       176.56607, 214.29639, 175.24173, 201.72075, 185.1842 , 192.448  ,\n",
      "       191.83661, 180.45816, 200.16185, 179.86438, 190.10783, 186.45903,\n",
      "       202.5786 , 186.65422, 207.39525, 298.71048, 211.20042, 184.53911,\n",
      "       208.0893 , 180.17535, 204.02248, 205.10622, 180.85837, 213.38538,\n",
      "       174.22559, 191.88275, 176.07819, 211.60562, 174.89801, 185.938  ,\n",
      "       175.13127, 211.13518, 181.23135, 179.93501, 174.26991, 207.82692,\n",
      "       213.22406, 174.25096], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 90, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([196.82346, 178.26562, 187.22438, 185.74545, 174.70512, 213.28296,\n",
      "       214.32874, 186.19838, 214.6368 , 184.97055, 192.31285, 179.82953,\n",
      "       175.62296, 212.32751, 175.06615, 197.19342, 185.69012, 187.4698 ,\n",
      "       188.76198, 178.70341, 191.81216, 179.82318, 189.28549, 186.02861,\n",
      "       201.55005, 185.4182 , 203.17825, 201.59627, 202.76657, 183.14542,\n",
      "       204.8079 , 179.91203, 198.87057, 193.76233, 180.0291 , 207.45288,\n",
      "       174.34229, 192.83963, 175.30315, 203.3262 , 174.29997, 180.55759,\n",
      "       175.00986, 201.02187, 183.10727, 179.7703 , 174.27133, 201.50089,\n",
      "       208.92429, 174.22537], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 100, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([184.18921, 175.01904, 185.86049, 184.88974, 174.45128, 205.80565,\n",
      "       211.91974, 185.31848, 214.63438, 184.92902, 188.17366, 179.81892,\n",
      "       175.02448, 202.12622, 174.9212 , 188.40466, 185.23642, 184.89766,\n",
      "       187.09636, 175.35124, 186.06416, 179.72847, 188.3196 , 185.42108,\n",
      "       201.41092, 179.73943, 201.3828 , 182.04297, 196.42505, 182.62   ,\n",
      "       202.10463, 179.8317 , 194.96059, 189.7368 , 180.18898, 200.3626 ,\n",
      "       174.2541 , 192.21791, 174.7711 , 199.91324, 174.3328 , 179.80379,\n",
      "       174.76239, 200.47076, 181.38495, 178.7443 , 174.23543, 195.28386,\n",
      "       203.83337, 174.22412], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 110, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([180.3865 , 174.35645, 184.23254, 184.71373, 174.23105, 191.91985,\n",
      "       199.03242, 184.77081, 214.61678, 184.41199, 187.38324, 179.68327,\n",
      "       174.6634 , 186.60089, 174.78934, 186.70529, 184.33481, 185.01257,\n",
      "       185.90018, 174.25655, 179.61967, 178.9886 , 186.53928, 184.25679,\n",
      "       200.63596, 174.9935 , 200.28944, 184.06302, 191.89755, 181.89783,\n",
      "       199.8887 , 179.8432 , 189.43167, 186.88634, 179.84232, 200.00111,\n",
      "       174.21802, 191.8501 , 174.4224 , 199.5059 , 174.24823, 178.58125,\n",
      "       174.56194, 199.85744, 181.15372, 175.61346, 174.22083, 187.84583,\n",
      "       202.45988, 174.22252], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 120, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([180.40967, 174.41214, 181.11603, 184.216  , 174.22758, 192.21071,\n",
      "       187.8886 , 184.39427, 214.50613, 184.32002, 187.26305, 178.59795,\n",
      "       174.45566, 187.14975, 174.67891, 185.82396, 183.4697 , 184.66864,\n",
      "       185.01926, 174.414  , 174.64215, 176.97336, 183.33627, 181.92113,\n",
      "       199.60564, 174.41423, 198.91597, 182.85437, 189.14436, 181.40952,\n",
      "       198.07657, 179.80142, 186.66498, 185.60616, 179.84827, 195.51714,\n",
      "       174.2241 , 191.90173, 174.30663, 199.48868, 174.22913, 177.39972,\n",
      "       174.46365, 197.19373, 180.65675, 174.26578, 174.21922, 183.46925,\n",
      "       202.62018, 174.22128], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 130, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([180.24422, 174.22765, 176.93385, 181.99889, 174.22787, 192.37267,\n",
      "       186.75389, 184.12569, 213.45123, 183.11523, 186.87018, 176.40392,\n",
      "       174.34174, 187.1615 , 174.58453, 183.5222 , 182.84167, 184.43681,\n",
      "       183.50262, 174.22684, 174.53406, 175.60905, 180.54524, 178.6127 ,\n",
      "       197.31824, 174.43022, 195.01591, 180.7853 , 187.72707, 180.9838 ,\n",
      "       196.58316, 179.54886, 184.90508, 183.2953 , 179.77808, 189.02257,\n",
      "       174.21811, 191.85306, 174.27206, 199.13425, 174.22025, 176.5357 ,\n",
      "       174.37997, 189.27988, 178.9759 , 174.4176 , 174.2184 , 179.56938,\n",
      "       202.54945, 174.22052], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 140, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.99455, 174.23508, 174.85696, 177.16855, 174.21802, 191.87047,\n",
      "       187.01967, 183.91934, 205.84456, 178.81071, 186.44664, 175.35759,\n",
      "       174.28075, 186.55823, 174.50465, 179.20287, 182.41011, 184.08363,\n",
      "       180.31808, 174.23444, 174.43663, 174.78096, 178.71687, 176.12633,\n",
      "       189.76343, 174.26645, 185.74966, 179.87854, 187.07033, 180.68254,\n",
      "       195.3274 , 177.84012, 182.314  , 178.85988, 179.15105, 186.54924,\n",
      "       174.21765, 191.84044, 174.25522, 197.50906, 174.21883, 175.84671,\n",
      "       174.32132, 180.7159 , 176.89265, 174.22525, 174.21768, 175.55078,\n",
      "       202.46362, 174.22032], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 150, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.9568 , 174.22206, 174.83078, 175.9754 , 174.21799, 191.79561,\n",
      "       186.58781, 183.73535, 200.00954, 176.04213, 185.83165, 174.75792,\n",
      "       174.24892, 186.51212, 174.43828, 174.99567, 182.05789, 181.06628,\n",
      "       176.832  , 174.2226 , 174.27187, 174.37791, 177.84453, 175.33002,\n",
      "       180.85486, 174.22441, 179.97253, 179.69708, 186.78094, 180.45993,\n",
      "       194.23862, 175.7667 , 178.1072 , 175.24393, 176.82216, 184.55608,\n",
      "       174.21758, 191.84251, 174.24641, 187.76628, 174.21802, 175.35072,\n",
      "       174.28296, 180.68713, 175.52263, 174.23903, 174.21765, 174.55637,\n",
      "       202.46259, 174.22014], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 160, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.9586 , 174.21996, 174.62326, 175.44325, 174.21774, 191.2107 ,\n",
      "       186.27162, 183.54498, 199.5334 , 175.24904, 184.73767, 174.34428,\n",
      "       174.23268, 185.8548 , 174.38431, 174.58061, 181.72835, 176.69469,\n",
      "       174.85011, 174.21819, 174.23026, 174.2873 , 177.32913, 175.1949 ,\n",
      "       180.5171 , 174.22633, 180.78351, 179.4067 , 186.65381, 180.30028,\n",
      "       193.26175, 174.87198, 174.97957, 174.93132, 175.47511, 181.01868,\n",
      "       174.21732, 191.841  , 174.24205, 186.44093, 174.21735, 174.99524,\n",
      "       174.25687, 180.26721, 175.10866, 174.22115, 174.21756, 174.2999 ,\n",
      "       202.4624 , 174.21992], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 170, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.95445, 174.21904, 174.50368, 174.99611, 174.21729, 185.81317,\n",
      "       183.72632, 183.33583, 199.6719 , 174.67252, 182.35905, 174.27673,\n",
      "       174.22458, 180.26437, 174.34131, 174.52484, 181.42181, 175.69194,\n",
      "       174.6303 , 174.21828, 174.22136, 174.25441, 177.09662, 175.10486,\n",
      "       180.20206, 174.2203 , 180.022  , 179.09055, 186.595  , 180.18877,\n",
      "       192.35774, 174.44778, 174.81497, 174.69765, 174.78885, 176.3093 ,\n",
      "       174.21733, 191.84016, 174.23892, 184.515  , 174.21745, 174.74654,\n",
      "       174.24048, 179.98082, 174.81157, 174.21872, 174.21756, 174.27194,\n",
      "       202.4544 , 174.21976], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 180, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.9537 , 174.21837, 174.42604, 174.79308, 174.21736, 180.26819,\n",
      "       176.71806, 183.10347, 199.39388, 174.4087 , 178.44238, 174.2569 ,\n",
      "       174.22066, 174.64214, 174.30783, 174.27142, 181.14658, 175.21713,\n",
      "       174.33821, 174.21732, 174.22116, 174.24463, 176.936  , 174.97238,\n",
      "       179.84734, 174.2191 , 180.02138, 178.77312, 186.56403, 180.11133,\n",
      "       191.50159, 174.30711, 174.63948, 174.56656, 174.3493 , 174.81305,\n",
      "       174.2173 , 191.83998, 174.23659, 180.95776, 174.21733, 174.57506,\n",
      "       174.23045, 180.00644, 174.67505, 174.2181 , 174.21753, 174.24825,\n",
      "       202.39122, 174.21956], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 190, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.95258, 174.21838, 174.38315, 174.62323, 174.2173 , 180.26826,\n",
      "       174.34805, 182.84511, 199.3797 , 174.31786, 175.27846, 174.24173,\n",
      "       174.21883, 174.42479, 174.28227, 174.25876, 180.90398, 174.82367,\n",
      "       174.24866, 174.21748, 174.21788, 174.2384 , 176.78546, 174.85236,\n",
      "       179.88641, 174.21895, 179.97333, 178.37221, 186.54422, 180.05803,\n",
      "       190.67865, 174.26422, 174.48372, 174.44728, 174.27832, 174.7821 ,\n",
      "       174.21732, 191.84016, 174.23483, 176.38718, 174.21739, 174.45764,\n",
      "       174.22449, 179.95279, 174.58084, 174.21739, 174.2175 , 174.21855,\n",
      "       201.89175, 174.21942], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 200, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.95227, 174.21828, 174.34937, 174.51521, 174.2173 , 180.23611,\n",
      "       174.504  , 182.55847, 199.38434, 174.28207, 174.62958, 174.23727,\n",
      "       174.21796, 174.50487, 174.26309, 174.2301 , 180.69322, 174.62462,\n",
      "       174.23212, 174.21729, 174.21748, 174.23586, 176.63452, 174.75066,\n",
      "       179.81876, 174.21846, 179.95718, 177.6987 , 186.5286 , 180.02193,\n",
      "       189.8807 , 174.2437 , 174.4282 , 174.40152, 174.25406, 174.55956,\n",
      "       174.21732, 191.84021, 174.23326, 174.79753, 174.21732, 174.3778 ,\n",
      "       174.2211 , 179.95943, 174.50533, 174.21744, 174.21754, 174.21985,\n",
      "       201.24426, 174.21931], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 210, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.9522 , 174.21823, 174.32889, 174.44322, 174.21729, 179.97523,\n",
      "       174.3664 , 182.24228, 199.37366, 174.26729, 174.63695, 174.2348 ,\n",
      "       174.2176 , 174.28157, 174.24908, 174.2243 , 180.51335, 174.4888 ,\n",
      "       174.2251 , 174.21736, 174.21744, 174.23384, 176.48541, 174.65672,\n",
      "       179.69138, 174.21832, 179.95584, 176.30557, 186.5143 , 179.9977 ,\n",
      "       189.10275, 174.23944, 174.38248, 174.3586 , 174.24283, 174.44919,\n",
      "       174.21729, 191.84021, 174.23204, 174.775  , 174.21736, 174.32393,\n",
      "       174.2192 , 179.9522 , 174.44469, 174.21733, 174.2175 , 174.21817,\n",
      "       200.47464, 174.2192 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 220, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.95213, 174.21822, 174.31262, 174.3937 , 174.2173 , 179.9646 ,\n",
      "       174.24019, 181.89632, 199.37152, 174.25859, 174.39993, 174.23276,\n",
      "       174.21748, 174.21971, 174.23898, 174.22232, 180.36273, 174.41096,\n",
      "       174.22223, 174.21729, 174.21738, 174.2324 , 176.3409 , 174.57108,\n",
      "       178.02621, 174.2183 , 179.95253, 175.18147, 186.50014, 179.98154,\n",
      "       188.34026, 174.23625, 174.35286, 174.33519, 174.23862, 174.40701,\n",
      "       174.2173 , 191.84003, 174.23096, 174.54243, 174.21736, 174.28766,\n",
      "       174.21828, 179.95305, 174.39653, 174.2173 , 174.21748, 174.21773,\n",
      "       199.94186, 174.21913], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 230, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.95216, 174.2182 , 174.30061, 174.36047, 174.21732, 179.9625 ,\n",
      "       174.23227, 181.5224 , 199.37189, 174.25313, 174.36055, 174.23138,\n",
      "       174.21736, 174.2261 , 174.23187, 174.22119, 180.23898, 174.36513,\n",
      "       174.2217 , 174.21729, 174.2173 , 174.23117, 176.20253, 174.49702,\n",
      "       175.9867 , 174.21822, 179.9527 , 174.6592 , 186.4858 , 179.97092,\n",
      "       187.58885, 174.23392, 174.33295, 174.31685, 174.23528, 174.36243,\n",
      "       174.2173 , 191.84012, 174.23001, 174.43721, 174.21732, 174.26349,\n",
      "       174.21774, 179.95216, 174.35855, 174.21732, 174.21745, 174.21732,\n",
      "       199.63373, 174.21906], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 240, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([179.95216, 174.21817, 174.29118, 174.33704, 174.21729, 179.95312,\n",
      "       174.22859, 181.12395, 199.37166, 174.24907, 174.3252 , 174.23018,\n",
      "       174.21735, 174.22069, 174.22693, 174.2205 , 180.13914, 174.33502,\n",
      "       174.22095, 174.21732, 174.21733, 174.2301 , 176.07056, 174.4354 ,\n",
      "       174.91422, 174.21819, 179.9522 , 174.49573, 186.47087, 179.96396,\n",
      "       186.84421, 174.23236, 174.31718, 174.30345, 174.23341, 174.34106,\n",
      "       174.21733, 191.84007, 174.22917, 174.39386, 174.21735, 174.24736,\n",
      "       174.2175 , 179.95227, 174.32874, 174.21725, 174.21742, 174.21735,\n",
      "       199.48163, 174.21898], dtype=float32)\n",
      "  batch_dim = 0\n",
      "     -> Agent : naive_qlearning\n",
      "step 0, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 470.3741 ,  205.94852,  341.3268 , 1026.6808 ,  461.85703,\n",
      "        245.45741,  217.00076,  561.7473 ,  216.9908 ,  215.12376,\n",
      "        216.96999,  210.2532 ,  239.97978,  197.80173,  217.00082,\n",
      "        341.1047 ,  217.00035,  546.12524,  211.48819,  217.00957,\n",
      "        229.8286 ,  256.36612,  295.79684,  321.06845,  217.00082,\n",
      "        315.25397,  643.22174, 1156.3646 , 1170.9464 ,  237.46136,\n",
      "        216.95772,  215.96051,  216.76547,  215.77634,  216.99942,\n",
      "        216.78223,  227.12228,  216.8132 ,  252.95505,  201.43071,\n",
      "        217.51552,  212.78738,  219.11453,  213.00403, 1144.3137 ,\n",
      "        216.97263,  216.9987 ,  229.7653 ,  286.18445,  216.83661],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 10, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 362.6739 ,  194.11174,  301.97772,  944.92267,  402.41434,\n",
      "        243.28159,  217.00066,  385.4025 ,  216.97235,  215.04443,\n",
      "        216.91753,  200.1093 ,  232.53842,  195.86115,  217.00081,\n",
      "        285.62756,  216.99973,  486.14594,  202.27887,  217.0042 ,\n",
      "        228.18279,  244.78067,  265.09845,  268.54944,  217.00081,\n",
      "        263.15   ,  583.25446, 1095.8884 , 1110.5939 ,  228.43896,\n",
      "        216.86263,  214.25314,  216.41742,  215.5513 ,  216.99551,\n",
      "        216.5764 ,  225.37805,  216.52606,  244.3089 ,  194.06839,\n",
      "        214.96588,  212.31007,  210.30383,  212.41359, 1081.8308 ,\n",
      "        216.90974,  216.99068,  223.6904 ,  275.3262 ,  216.5812 ],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 20, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 253.19373,  194.17378,  259.27457,  827.8925 ,  344.40884,\n",
      "        241.12033,  217.00027,  309.37854,  216.91592,  215.00807,\n",
      "        216.77014,  185.94649,  227.08829,  194.89182,  217.00078,\n",
      "        237.37047,  216.99709,  426.542  ,  189.74037,  217.00247,\n",
      "        226.62465,  233.70175,  236.9939 ,  226.90959,  217.00075,\n",
      "        222.63986,  523.3999 , 1035.3848 , 1050.2887 ,  216.60863,\n",
      "        216.5638 ,  209.76218,  216.05643,  215.36856,  216.98317,\n",
      "        216.29852,  223.77133,  216.00885,  236.44334,  192.97343,\n",
      "        210.38785,  211.90106,  203.37776,  212.20456, 1015.241  ,\n",
      "        216.7235 ,  216.94543,  218.86781,  265.03976,  215.98016],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 30, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([204.20464, 194.03198, 237.75833, 627.1818 , 290.34137, 238.85783,\n",
      "       216.99893, 269.8944 , 216.73366, 214.99878, 216.39058, 182.20274,\n",
      "       222.8546 , 194.04248, 217.0008 , 204.24112, 216.98792, 368.14886,\n",
      "       182.68085, 217.00186, 225.1573 , 225.02316, 224.47664, 203.03003,\n",
      "       217.0007 , 200.32205, 463.786  , 974.53485, 990.03644, 207.11142,\n",
      "       215.51024, 200.1571 , 215.74551, 215.22998, 216.9379 , 215.99416,\n",
      "       222.31311, 215.49303, 229.06668, 190.36218, 203.68774, 210.98233,\n",
      "       201.9162 , 211.98952, 934.0248 , 216.06183, 216.68997, 215.4782 ,\n",
      "       255.20403, 214.89865], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 40, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([190.74078, 193.70555, 233.04039, 376.2433 , 244.73932, 236.09164,\n",
      "       216.99196, 247.35884, 216.23915, 214.99158, 215.88722, 181.80765,\n",
      "       219.47278, 192.51833, 217.00076, 189.41937, 216.94939, 312.92618,\n",
      "       182.80832, 217.00159, 223.72295, 219.90462, 218.89531, 194.90411,\n",
      "       217.00056, 193.16385, 404.7568 , 911.9683 , 929.8396 , 198.43393,\n",
      "       211.6231 , 192.75262, 215.49744, 215.12947, 216.74754, 215.69057,\n",
      "       220.99889, 214.47916, 221.28242, 185.98149, 203.51474, 207.83592,\n",
      "       201.24196, 211.84439, 800.2539 , 213.49835, 215.186  , 213.81769,\n",
      "       244.9951 , 213.85387], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 50, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([187.03731, 193.75262, 231.80524, 280.22873, 213.3245 , 233.03001,\n",
      "       216.9431 , 233.20563, 215.7198 , 214.95299, 215.88916, 181.62415,\n",
      "       216.2224 , 188.03682, 217.00038, 187.04031, 216.76389, 263.86734,\n",
      "       181.52144, 217.00134, 221.98763, 217.0502 , 215.13867, 193.40375,\n",
      "       216.99934, 192.00494, 347.20657, 841.2374 , 869.69995, 194.73651,\n",
      "       200.61024, 192.88637, 215.28876, 215.04486, 215.85524, 215.30829,\n",
      "       219.79692, 210.0675 , 212.49327, 181.24687, 203.27739, 198.3342 ,\n",
      "       200.63495, 211.72472, 532.9061 , 204.7949 , 207.83185, 213.0064 ,\n",
      "       232.37706, 213.55244], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 60, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([185.9512 , 193.69844, 230.8379 , 251.36363, 198.03917, 231.20366,\n",
      "       216.54951, 223.0741 , 215.12628, 214.7456 , 215.69461, 181.4094 ,\n",
      "       210.39497, 181.6156 , 216.99826, 186.27141, 215.78447, 226.18456,\n",
      "       181.4799 , 217.0013 , 218.27634, 214.30693, 213.48756, 192.68991,\n",
      "       216.99283, 191.59085, 293.28766, 731.4829 , 809.61676, 191.6471 ,\n",
      "       192.90755, 191.74895, 214.99324, 214.87944, 211.6064 , 214.42876,\n",
      "       218.57811, 197.73344, 199.74225, 180.09138, 202.78574, 190.58026,\n",
      "       200.24858, 211.59084, 312.91428, 193.66069, 191.76628, 211.6778 ,\n",
      "       221.18454, 213.6008 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 70, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([185.38875, 193.66972, 228.77312, 240.64969, 192.97205, 229.49818,\n",
      "       214.92763, 215.2216 , 211.609  , 213.47054, 214.91983, 181.42737,\n",
      "       196.6952 , 181.3929 , 216.98523, 184.37006, 210.69385, 204.53375,\n",
      "       181.43346, 217.00111, 206.56158, 207.04549, 212.87839, 191.84843,\n",
      "       216.95299, 190.56079, 247.1257 , 486.8659 , 749.5758 , 186.82515,\n",
      "       188.9479 , 191.65813, 213.88951, 214.0546 , 198.29517, 212.391  ,\n",
      "       216.78767, 194.58679, 195.76425, 179.83847, 202.51527, 190.93344,\n",
      "       199.862  , 211.18626, 259.08087, 194.49022, 185.0011 , 209.11517,\n",
      "       219.45432, 213.5632 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 80, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([184.87935, 193.48657, 221.10907, 233.79526, 191.6683 , 227.64613,\n",
      "       213.40488, 209.2609 , 198.5576 , 206.09729, 210.31035, 181.38591,\n",
      "       192.57768, 181.09012, 216.90028, 183.3036 , 196.02672, 195.88089,\n",
      "       181.39153, 217.00098, 193.8471 , 192.76622, 212.61484, 191.87473,\n",
      "       216.68915, 190.53798, 212.7935 , 282.9266 , 689.4965 , 181.2614 ,\n",
      "       184.49648, 190.02069, 208.05435, 208.99817, 195.28056, 209.44826,\n",
      "       212.67932, 193.06784, 193.00671, 179.62474, 202.272  , 190.61964,\n",
      "       199.32205, 209.44157, 244.76837, 193.26895, 182.04306, 202.36565,\n",
      "       218.50813, 213.52307], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 90, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([184.3625 , 193.00587, 206.82678, 227.9713 , 190.41692, 225.60756,\n",
      "       213.0593 , 205.0788 , 193.28613, 203.31139, 195.34401, 181.38786,\n",
      "       191.12273, 180.78433, 216.39873, 182.49524, 195.78406, 193.08974,\n",
      "       181.39058, 216.99995, 186.36606, 192.51393, 212.44705, 191.772  ,\n",
      "       214.9426 , 190.4895 , 188.71773, 236.54195, 629.1792 , 179.82715,\n",
      "       181.2588 , 184.77693, 192.65883, 203.9601 , 192.03108, 202.25948,\n",
      "       201.9018 , 193.2285 , 191.81012, 179.49573, 201.97969, 190.4036 ,\n",
      "       198.41843, 203.03421, 236.06226, 193.1377 , 181.08255, 202.15005,\n",
      "       214.15213, 213.25757], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 100, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([183.85446, 192.45679, 204.72798, 222.39258, 187.48332, 223.64838,\n",
      "       210.34482, 202.2904 , 186.8317 , 202.80469, 194.20232, 181.38611,\n",
      "       191.21507, 180.6588 , 215.1173 , 181.97559, 193.77934, 191.98506,\n",
      "       181.38538, 216.99146, 182.78453, 191.80638, 212.16275, 191.75807,\n",
      "       206.21071, 190.42203, 184.67258, 223.20006, 568.77094, 179.53148,\n",
      "       181.20491, 181.53055, 193.05986, 202.23193, 187.18054, 200.68927,\n",
      "       201.09491, 192.47084, 191.01714, 179.4166 , 201.56804, 190.4209 ,\n",
      "       196.17987, 200.65723, 227.86633, 193.10768, 181.02275, 201.9516 ,\n",
      "       200.47964, 209.77977], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 110, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([183.37653, 192.0806 , 203.8344 , 216.84927, 186.59085, 221.88762,\n",
      "       198.25075, 200.5754 , 183.02423, 202.17151, 189.60242, 181.38434,\n",
      "       190.99983, 180.47028, 210.12639, 181.64793, 193.04637, 191.7852 ,\n",
      "       181.3789 , 216.92325, 180.58818, 191.20833, 211.55269, 191.7495 ,\n",
      "       191.96944, 190.40186, 184.44707, 215.55995, 508.6675 , 179.46066,\n",
      "       181.10965, 181.01407, 190.65831, 201.39578, 181.57298, 199.91142,\n",
      "       201.05737, 191.89197, 189.35854, 179.35963, 200.81528, 190.37918,\n",
      "       189.34024, 199.88489, 219.05753, 192.97324, 181.03024, 201.59499,\n",
      "       194.32639, 192.13116], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 120, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([182.94305, 191.8725 , 202.77087, 211.57085, 185.42563, 219.51904,\n",
      "       193.32648, 199.56413, 181.30528, 201.74841, 184.41994, 181.38445,\n",
      "       190.89285, 180.29317, 193.66985, 181.44727, 187.64058, 191.77557,\n",
      "       181.33296, 216.56044, 180.31119, 190.56357, 210.93448, 191.74825,\n",
      "       192.29518, 190.39296, 183.52985, 209.26576, 449.09302, 179.43839,\n",
      "       181.03017, 181.0599 , 190.44084, 200.45752, 181.25378, 197.4428 ,\n",
      "       200.58125, 191.80777, 183.8937 , 179.33296, 200.01585, 190.37964,\n",
      "       181.14928, 198.78548, 210.71873, 192.30162, 181.00409, 201.18256,\n",
      "       182.46005, 185.00221], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 130, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([182.56157, 191.77151, 201.91803, 207.17468, 184.24915, 209.76062,\n",
      "       191.00171, 198.96382, 181.30588, 201.30856, 181.28134, 181.3844 ,\n",
      "       190.53574, 180.12936, 194.19188, 181.32404, 182.45944, 191.7583 ,\n",
      "       181.0734 , 215.86479, 180.20847, 186.33447, 210.44797, 191.7477 ,\n",
      "       192.29164, 190.386  , 183.09573, 204.51233, 390.45773, 179.41632,\n",
      "       180.98164, 180.96748, 190.15123, 199.72505, 181.13666, 188.76944,\n",
      "       200.06337, 191.75562, 180.7676 , 179.31863, 198.70337, 190.3787 ,\n",
      "       179.93419, 195.9568 , 205.22964, 187.49045, 180.92719, 200.53452,\n",
      "       180.7886 , 181.61917], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 140, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([182.23528, 191.72496, 201.19467, 204.20343, 183.29787, 204.94284,\n",
      "       190.83502, 198.5787 , 181.10551, 200.61342, 181.12477, 181.38431,\n",
      "       187.38438, 179.97675, 193.63947, 181.25023, 181.53485, 191.75815,\n",
      "       181.01129, 214.74129, 180.12459, 181.08951, 208.98805, 191.74728,\n",
      "       191.78468, 190.3815 , 182.63187, 201.96628, 333.89642, 179.39717,\n",
      "       180.96994, 180.82104, 187.68176, 197.98041, 181.0652 , 181.11943,\n",
      "       199.3589 , 191.75253, 180.53708, 179.31087, 194.55168, 190.37679,\n",
      "       179.95485, 185.94284, 202.88252, 182.04562, 180.75494, 199.02023,\n",
      "       180.23553, 181.32047], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 150, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.96436, 191.66899, 200.3437 , 202.6029 , 182.5838 , 203.12039,\n",
      "       190.65106, 198.29205, 181.00557, 199.03242, 181.12282, 181.38434,\n",
      "       181.76497, 179.84549, 192.78699, 181.20488, 181.59763, 191.75275,\n",
      "       180.9953 , 206.95448, 180.06085, 180.17018, 203.71147, 191.74721,\n",
      "       191.71606, 190.37903, 182.2612 , 201.04294, 282.09323, 179.38173,\n",
      "       180.85265, 180.57268, 182.11475, 192.20328, 181.01569, 182.1114 ,\n",
      "       197.98361, 191.73698, 180.2156 , 179.30695, 186.02657, 190.37675,\n",
      "       179.48569, 179.61072, 202.16243, 181.18262, 180.52016, 192.68431,\n",
      "       179.79233, 180.99596], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 160, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.7455 , 191.21669, 198.6978 , 201.88843, 182.06924, 199.79991,\n",
      "       190.06302, 198.03871, 180.99081, 193.20111, 181.03949, 181.3843 ,\n",
      "       180.01305, 179.73463, 190.17598, 181.17686, 181.43361, 191.75133,\n",
      "       180.98636, 202.29993, 179.9965 , 180.2174 , 202.42584, 191.74718,\n",
      "       191.24574, 190.3778 , 181.98215, 200.80983, 239.85963, 179.37111,\n",
      "       180.45596, 180.28566, 179.47163, 183.331  , 180.98433, 181.05132,\n",
      "       193.48111, 191.65807, 180.05371, 179.30493, 181.1472 , 190.37679,\n",
      "       179.52379, 180.42302, 201.9559 , 181.3419 , 180.26349, 182.15163,\n",
      "       179.78357, 180.94983], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 170, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.5733 , 190.61284, 192.12895, 201.60736, 181.71027, 191.35909,\n",
      "       185.71144, 197.78209, 180.98924, 183.603  , 180.99557, 181.3843 ,\n",
      "       179.92522, 179.64308, 183.72455, 181.15906, 181.38733, 191.7501 ,\n",
      "       180.98279, 200.42705, 179.93716, 180.06802, 200.84056, 191.74716,\n",
      "       186.63199, 190.37715, 181.75493, 200.77356, 212.10287, 179.36488,\n",
      "       179.9585 , 180.01865, 179.47775, 181.59015, 180.98347, 181.12186,\n",
      "       183.91762, 191.40428, 180.03677, 179.3041 , 181.86136, 190.3767 ,\n",
      "       179.4506 , 179.41444, 201.72803, 181.17409, 180.02478, 181.93886,\n",
      "       179.70613, 180.81334], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 180, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.44014, 190.4562 , 180.90352, 201.50363, 181.46521, 183.68207,\n",
      "       179.98056, 197.4998 , 180.9844 , 181.92273, 180.98459, 181.38432,\n",
      "       179.81134, 179.5687 , 181.36758, 181.14716, 181.39516, 191.74977,\n",
      "       180.98209, 196.47508, 179.88434, 180.02467, 198.95082, 191.74715,\n",
      "       181.14462, 190.37683, 181.58568, 200.77031, 198.57422, 179.36041,\n",
      "       179.61725, 179.80464, 179.4072 , 181.58012, 180.96364, 180.98972,\n",
      "       179.9987 , 191.0411 , 180.01437, 179.30367, 181.14145, 190.37671,\n",
      "       179.44214, 179.5144 , 201.22238, 181.11012, 179.82855, 181.16927,\n",
      "       179.70059, 180.68716], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 190, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.33751, 190.39746, 180.72821, 201.46425, 181.29984, 183.84453,\n",
      "       179.65338, 197.17552, 180.98346, 181.89914, 180.98622, 181.38432,\n",
      "       179.78036, 179.50897, 181.20744, 181.1388 , 181.38765, 191.74947,\n",
      "       180.98206, 186.27414, 179.83461, 180.00629, 191.30746, 191.7472 ,\n",
      "       180.64641, 190.37666, 181.45717, 200.76549, 193.62715, 179.35649,\n",
      "       179.43387, 179.64543, 179.33487, 181.12775, 180.83908, 180.99802,\n",
      "       180.50105, 190.78708, 179.99359, 179.30353, 181.17947, 190.37659,\n",
      "       179.426  , 179.37773, 201.21245, 181.11247, 179.67757, 180.9292 ,\n",
      "       179.68243, 180.52538], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 200, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.25769, 190.38205, 179.87311, 201.4461 , 181.18939, 182.78397,\n",
      "       179.59625, 196.79488, 180.9833 , 181.39703, 180.98372, 181.38432,\n",
      "       179.75629, 179.46152, 181.0784 , 181.13278, 181.38464, 191.74937,\n",
      "       180.98195, 181.62955, 179.78773, 179.97876, 179.40692, 191.74712,\n",
      "       180.5142 , 190.3766 , 181.36078, 200.75853, 192.16418, 179.35289,\n",
      "       179.35066, 179.53206, 179.32791, 181.16458, 180.59428, 180.98236,\n",
      "       179.74014, 190.62189, 179.9765 , 179.30347, 181.11565, 190.37665,\n",
      "       179.41689, 179.3851 , 201.22458, 181.10422, 179.56575, 180.83398,\n",
      "       179.67436, 180.3586 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 210, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.19395, 190.37762, 179.65054, 201.43405, 181.11641, 182.50613,\n",
      "       179.39009, 196.34357, 180.98308, 181.45744, 180.98341, 181.38435,\n",
      "       179.73122, 179.42424, 181.01904, 181.1282 , 181.3847 , 191.74919,\n",
      "       180.98193, 182.20114, 179.74377, 179.95651, 180.95892, 191.7472 ,\n",
      "       180.12698, 190.37656, 181.28935, 200.75165, 191.79568, 179.34961,\n",
      "       179.31812, 179.45384, 179.31554, 181.1069 , 180.24506, 180.9843 ,\n",
      "       179.78825, 190.52142, 179.95909, 179.30344, 181.1108 , 190.37663,\n",
      "       179.40872, 179.36562, 201.20752, 181.10222, 179.48485, 180.76355,\n",
      "       179.66486, 180.19684], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 220, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.14185, 190.37682, 179.57112, 201.4234 , 181.06853, 182.22508,\n",
      "       179.37794, 195.80751, 180.98286, 181.38464, 180.98334, 181.38431,\n",
      "       179.71394, 179.39517, 180.98952, 181.1246 , 181.38435, 191.74907,\n",
      "       180.9819 , 181.39346, 179.70255, 179.9361 , 179.35661, 191.7471 ,\n",
      "       179.90065, 190.37656, 181.23677, 200.74513, 191.71802, 179.34665,\n",
      "       179.30719, 179.40091, 179.30853, 181.1082 , 179.92624, 180.98196,\n",
      "       179.6713 , 190.46172, 179.94193, 179.30347, 181.10579, 190.37662,\n",
      "       179.40189, 179.3638 , 201.19681, 181.10251, 179.42732, 180.70859,\n",
      "       179.65694, 180.04782], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 230, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.09914, 190.37659, 179.53136, 201.41281, 181.0374 , 182.03886,\n",
      "       179.35042, 195.1745 , 180.98271, 181.3935 , 180.98325, 181.38434,\n",
      "       179.6963 , 179.37273, 180.98975, 181.12178, 181.38434, 191.74896,\n",
      "       180.98195, 181.49054, 179.66425, 179.9173 , 179.54477, 191.74716,\n",
      "       179.71042, 190.37657, 181.19832, 200.73882, 191.70622, 179.34398,\n",
      "       179.30412, 179.36572, 179.3061 , 181.10278, 179.68881, 180.98227,\n",
      "       179.6487 , 190.4269 , 179.92476, 179.30345, 181.1042 , 190.37666,\n",
      "       179.39575, 179.35954, 201.19199, 181.10199, 179.38702, 180.65884,\n",
      "       179.64902, 179.91609], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 240, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([181.065  , 190.37653, 179.51112, 201.40193, 181.01723, 181.89182,\n",
      "       179.32706, 194.43808, 180.98236, 181.38423, 180.98317, 181.38435,\n",
      "       179.67996, 179.35553, 180.98378, 181.11945, 181.38435, 191.74884,\n",
      "       180.9819 , 181.38496, 179.62875, 179.89975, 179.35484, 191.7472 ,\n",
      "       179.59438, 190.37654, 181.17033, 200.7325 , 191.70526, 179.34149,\n",
      "       179.30351, 179.34265, 179.30484, 181.1025 , 179.53232, 180.98196,\n",
      "       179.61256, 190.40674, 179.90762, 179.30344, 181.10374, 190.37656,\n",
      "       179.39014, 179.35695, 201.18752, 181.1019 , 179.35922, 180.60878,\n",
      "       179.64159, 179.8031 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "     -> Agent : aif_1d\n",
      "step 0, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 869.0546 ,  996.3947 ,  352.97864, 2142.4253 , 1031.8243 ,\n",
      "       1013.1876 ,  870.0655 , 1820.9971 ,  875.8243 ,  361.16998,\n",
      "        358.963  ,  448.59253, 1391.7739 ,  455.86334, 1213.2623 ,\n",
      "        400.59387,  591.0118 ,  463.06744,  351.32562,  362.19824,\n",
      "        442.79355,  818.1574 ,  365.6358 ,  366.28064,  365.0296 ,\n",
      "        346.33148,  363.54117, 1438.6832 ,  366.2126 ,  909.50714,\n",
      "        326.14136,  660.77704,  330.63232,  621.07025,  544.54346,\n",
      "        820.5531 ,  339.5522 ,  739.7932 , 2452.413  ,  942.0727 ,\n",
      "       1386.5948 , 1365.7473 ,  972.7323 ,  339.1902 , 1043.3033 ,\n",
      "        808.2778 ,  472.4693 ,  784.44275, 1922.6052 ,  363.49353],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 10, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 781.1399 ,  921.0113 ,  347.02716, 1962.8121 ,  904.19885,\n",
      "        941.6488 ,  380.7551 , 1730.9298 ,  755.3384 ,  357.6709 ,\n",
      "        340.61395,  423.06848, 1345.3406 ,  430.52124, 1073.8778 ,\n",
      "        370.4604 ,  550.23987,  436.50027,  350.32074,  358.23163,\n",
      "        417.0976 ,  729.7837 ,  362.2437 ,  359.547  ,  351.4162 ,\n",
      "        345.48065,  363.50323, 1173.379  ,  358.74084,  822.10394,\n",
      "        323.08417,  594.29724,  322.38257,  462.40698,  495.44492,\n",
      "        758.06305,  330.3766 ,  607.2898 , 2272.2559 ,  826.1305 ,\n",
      "       1156.9609 , 1287.408  ,  884.96295,  331.29376,  971.1743 ,\n",
      "        714.911  ,  438.15002,  711.1291 , 1690.4524 ,  362.052  ],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 20, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 702.09283,  846.4317 ,  343.27203, 1769.0044 ,  820.7444 ,\n",
      "        874.6963 ,  345.80344, 1645.738  ,  632.8705 ,  351.61945,\n",
      "        329.20874,  402.0899 , 1301.3301 ,  409.75293,  926.6012 ,\n",
      "        347.08646,  514.04144,  414.19147,  349.12183,  346.62347,\n",
      "        395.61685,  638.6793 ,  361.51917,  355.7559 ,  342.99365,\n",
      "        344.65234,  363.44513,  893.1771 ,  354.69446,  739.6891 ,\n",
      "        321.98666,  536.8324 ,  314.65454,  353.84122,  453.59082,\n",
      "        701.5482 ,  322.31506,  544.8968 , 2101.787  ,  749.6736 ,\n",
      "        840.2003 , 1208.9059 ,  806.40063,  322.95343,  842.85126,\n",
      "        616.6954 ,  412.40826,  647.7598 , 1466.4059 ,  362.05377],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 30, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 631.48456,  784.896  ,  338.28754, 1503.5348 ,  746.4447 ,\n",
      "        812.58044,  340.93954, 1562.4065 ,  516.41833,  343.42548,\n",
      "        320.76324,  385.7832 , 1256.2064 ,  393.65433,  757.9375 ,\n",
      "        329.4968 ,  482.55096,  395.4921 ,  347.47513,  339.56537,\n",
      "        378.67395,  540.8907 ,  361.5361 ,  353.43213,  337.6148 ,\n",
      "        343.84607,  363.28122,  697.4222 ,  352.26154,  663.4099 ,\n",
      "        320.9618 ,  488.293  ,  308.6949 ,  319.64172,  417.8244 ,\n",
      "        650.2005 ,  315.34552,  497.268  , 1935.6052 ,  690.4013 ,\n",
      "        602.687  , 1131.365  ,  737.5289 ,  315.09515,  622.05695,\n",
      "        515.38354,  393.8277 ,  593.4035 , 1271.8904 ,  362.05005],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 40, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 565.70764,  729.47675,  329.65262, 1150.9609 ,  680.4579 ,\n",
      "        754.6782 ,  334.74152, 1476.7124 ,  427.16193,  334.55075,\n",
      "        314.07587,  373.7989 , 1203.771  ,  381.831  ,  571.36096,\n",
      "        316.97272,  455.04523,  377.97223,  345.98593,  336.54944,\n",
      "        366.91754,  450.3167 ,  361.53943,  349.68958,  334.14783,\n",
      "        343.05457,  362.69983,  606.0658 ,  351.0766 ,  607.6817 ,\n",
      "        320.0691 ,  446.31476,  303.81915,  315.89993,  387.5252 ,\n",
      "        603.9896 ,  309.1421 ,  457.0357 , 1771.5154 ,  638.61426,\n",
      "        497.53845, 1050.5793 ,  678.10846,  307.6034 ,  408.7143 ,\n",
      "        428.57056,  379.72858,  546.50476, 1117.8344 ,  362.00766],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 50, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 503.1374 ,  680.0895 ,  319.02832,  871.6067 ,  624.0287 ,\n",
      "        696.6527 ,  326.4817 , 1386.6241 ,  373.97296,  327.38995,\n",
      "        308.18723,  365.43872, 1152.0173 ,  373.29578,  419.65582,\n",
      "        308.4392 ,  428.16504,  358.74255,  345.20392,  334.45526,\n",
      "        358.61414,  385.594  ,  361.46344,  335.49185,  332.5454 ,\n",
      "        342.24207,  361.1953 ,  556.34424,  350.09814,  558.51733,\n",
      "        319.1923 ,  404.61285,  299.97134,  314.9301 ,  361.82822,\n",
      "        562.6387 ,  301.67545,  420.9735 , 1595.8933 ,  593.15015,\n",
      "        455.5744 ,  958.4269 ,  627.3714 ,  300.22867,  313.2823 ,\n",
      "        368.43857,  366.17993,  505.79996, 1001.56494,  362.01062],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 60, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 462.8697 ,  635.2687 ,  309.46423,  750.4391 ,  574.7954 ,\n",
      "        632.6779 ,  322.95822, 1299.6075 ,  349.77536,  320.79678,\n",
      "        302.5443 ,  359.8172 , 1095.5156 ,  365.4795 ,  355.7038 ,\n",
      "        302.64758,  395.65622,  339.09454,  344.2057 ,  330.4823 ,\n",
      "        353.1833 ,  352.94437,  361.1884 ,  328.5381 ,  331.10992,\n",
      "        341.22366,  359.21448,  517.7198 ,  349.02783,  518.3316 ,\n",
      "        318.35535,  376.83987,  296.40723,  313.3201 ,  341.04013,\n",
      "        525.47235,  291.83545,  392.2608 , 1404.6204 ,  553.2715 ,\n",
      "        427.2732 ,  853.1562 ,  584.2578 ,  291.6341 ,  301.69574,\n",
      "        339.62927,  345.99832,  470.47974,  908.5034 ,  362.0042 ],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 70, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 428.25183,  595.20013,  301.6958 ,  682.13007,  531.86163,\n",
      "        588.5386 ,  319.9598 , 1213.172  ,  339.30313,  313.27982,\n",
      "        298.92926,  355.93036, 1027.0568 ,  350.74365,  341.5369 ,\n",
      "        297.81195,  380.25964,  322.35938,  342.4634 ,  324.9607 ,\n",
      "        349.61975,  342.52728,  359.64774,  322.7727 ,  329.90363,\n",
      "        339.14603,  350.3776 ,  483.38712,  346.97986,  484.16925,\n",
      "        317.5652 ,  357.7718 ,  290.4694 ,  311.33997,  324.79834,\n",
      "        492.41504,  287.5176 ,  369.01892, 1209.1841 ,  518.082  ,\n",
      "        403.93408,  722.22186,  547.40265,  286.56192,  300.927  ,\n",
      "        331.76788,  338.67578,  439.90048,  828.2451 ,  361.98724],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 80, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 400.6804 ,  558.8048 ,  292.87018,  623.2856 ,  493.9815 ,\n",
      "        547.4907 ,  317.2493 , 1122.1362 ,  333.63165,  303.0905 ,\n",
      "        295.88452,  352.4353 ,  878.90295,  343.51392,  335.91226,\n",
      "        289.78674,  367.3463 ,  307.5669 ,  336.22034,  317.92734,\n",
      "        347.19806,  340.4891 ,  351.0671 ,  317.42462,  328.77444,\n",
      "        334.96643,  334.5965 ,  452.9701 ,  340.63388,  455.27136,\n",
      "        316.71896,  345.302  ,  286.39255,  309.26074,  311.9887 ,\n",
      "        464.48285,  283.9104 ,  349.99338,  999.2166 ,  487.17538,\n",
      "        384.2856 ,  580.1175 ,  514.057  ,  283.59604,  300.05603,\n",
      "        329.51312,  333.15964,  413.60812,  757.11316,  361.88242],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 90, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([ 379.01318,  526.2285 ,  285.12903,  570.4566 ,  460.36163,\n",
      "        506.94363,  314.94604, 1012.3533 ,  329.60144,  299.6201 ,\n",
      "        293.54495,  349.88208,  527.28815,  339.7543 ,  332.62332,\n",
      "        286.59042,  358.32858,  300.97397,  327.22113,  310.45392,\n",
      "        344.95996,  340.31564,  338.6553 ,  310.3423 ,  327.69907,\n",
      "        326.26315,  332.69415,  426.2591 ,  326.69238,  430.73697,\n",
      "        315.47018,  335.7605 ,  284.1004 ,  306.8748 ,  301.9093 ,\n",
      "        440.17233,  281.49725,  334.41833,  789.52826,  460.26837,\n",
      "        367.80695,  453.3427 ,  475.23987,  281.4571 ,  298.8433 ,\n",
      "        328.66302,  330.55206,  391.0584 ,  693.953  ,  361.2724 ],      dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 100, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([361.91962, 498.24478, 281.40237, 523.53436, 430.5616 , 469.57593,\n",
      "       313.03192, 849.25226, 325.58295, 296.80884, 291.65546, 345.96295,\n",
      "       316.49396, 337.25653, 330.57092, 284.02853, 351.96167, 296.77084,\n",
      "       323.12537, 302.86346, 339.17712, 340.35364, 335.78488, 303.30078,\n",
      "       326.6735 , 311.0901 , 330.34335, 403.11542, 309.94086, 409.79443,\n",
      "       313.41312, 328.87286, 281.48096, 303.5788 , 294.18655, 419.09918,\n",
      "       280.04688, 321.28644, 621.21094, 436.95526, 353.67822, 370.8662 ,\n",
      "       448.23984, 280.00046, 297.48767, 327.4685 , 328.7008 , 371.78564,\n",
      "       638.1362 , 358.07758], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 110, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([348.70364, 473.41617, 278.8457 , 482.74683, 404.3063 , 438.28964,\n",
      "       311.4641 , 585.69324, 323.53192, 294.61032, 290.09473, 332.6186 ,\n",
      "       309.9624 , 333.80914, 329.07938, 282.81024, 346.5255 , 293.95605,\n",
      "       319.35266, 297.75668, 320.75858, 340.35736, 333.5259 , 297.438  ,\n",
      "       325.68527, 297.8587 , 328.20123, 383.1301 , 296.73874, 391.99243,\n",
      "       312.7144 , 323.9297 , 280.13907, 301.74762, 288.33496, 401.091  ,\n",
      "       278.76743, 309.50067, 569.5752 , 416.8559 , 341.3858 , 341.1151 ,\n",
      "       426.3079 , 278.8531 , 296.1253 , 326.2967 , 327.1053 , 355.38086,\n",
      "       589.0857 , 344.68408], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 120, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([338.5953 , 450.5318 , 276.69037, 448.32465, 381.2722 , 411.62183,\n",
      "       310.193  , 369.46582, 321.90887, 292.45105, 288.79028, 329.8192 ,\n",
      "       311.69693, 331.3865 , 327.93967, 281.80136, 341.28226, 291.89682,\n",
      "       316.351  , 293.9449 , 319.64883, 340.33862, 330.23444, 293.10886,\n",
      "       324.72974, 288.57745, 326.56467, 365.96436, 290.06516, 376.9823 ,\n",
      "       312.04022, 320.304  , 279.09323, 299.89456, 283.9244 , 385.80545,\n",
      "       277.72217, 300.6929 , 531.18146, 399.62097, 332.49786, 337.18726,\n",
      "       408.26892, 277.89124, 294.81046, 325.31036, 325.77246, 341.5216 ,\n",
      "       546.2126 , 334.57205], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 130, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([330.909  , 429.74384, 275.77295, 419.17773, 361.57288, 388.93945,\n",
      "       309.17572, 348.2671 , 320.6238 , 290.24738, 287.66824, 328.10443,\n",
      "       311.74847, 329.4406 , 327.03296, 280.872  , 336.71735, 290.26404,\n",
      "       314.98   , 290.6142 , 318.9332 , 340.32098, 328.38324, 290.04974,\n",
      "       323.80273, 277.19696, 325.31134, 351.29816, 286.14655, 364.39478,\n",
      "       311.3313 , 317.61475, 278.31024, 298.02826, 280.6141 , 372.91568,\n",
      "       276.8341 , 293.8909 , 493.05508, 384.92117, 325.47668, 334.0556 ,\n",
      "       392.48682, 277.0565 , 293.54803, 324.39188, 324.60297, 329.9337 ,\n",
      "       508.9329 , 330.07654], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 140, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([325.08734, 411.56702, 274.8526 , 394.5974 , 344.80386, 369.727  ,\n",
      "       308.37228, 340.24518, 319.58215, 288.2038 , 286.6751 , 326.53998,\n",
      "       310.97134, 327.7021 , 326.2281 , 280.06958, 333.04053, 288.9498 ,\n",
      "       314.07776, 287.85   , 317.56027, 340.31085, 326.90173, 287.90717,\n",
      "       322.9013 , 275.33066, 324.16568, 338.8498 , 283.39432, 353.89777,\n",
      "       310.6686 , 315.57996, 277.6126 , 296.24786, 278.10974, 362.11243,\n",
      "       276.039  , 288.50876, 459.86597, 372.4526 , 319.90005, 330.4328 ,\n",
      "       378.87463, 276.30676, 292.2558 , 323.49548, 323.51697, 320.2459 ,\n",
      "       476.68423, 327.96442], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 150, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([320.67676, 395.891  , 274.1351 , 373.87958, 330.8097 , 353.405  ,\n",
      "       307.7462 , 331.05298, 318.65363, 285.75055, 285.77286, 324.97424,\n",
      "       307.20837, 326.14536, 325.47107, 279.32883, 330.09424, 287.83783,\n",
      "       313.3155 , 286.25153, 316.58734, 340.30612, 325.50095, 286.34088,\n",
      "       322.0232 , 273.88   , 323.0632 , 328.33966, 281.66638, 345.19122,\n",
      "       310.02594, 313.9913 , 276.9332 , 294.51645, 276.18246, 353.10748,\n",
      "       275.3013 , 284.27594, 433.2741 , 361.93414, 315.5795 , 327.85648,\n",
      "       367.43402, 275.61353, 290.21652, 322.62073, 322.49652, 312.35175,\n",
      "       448.9367 , 326.4677 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 160, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([317.31647, 382.44427, 273.46527, 356.56726, 318.9644 , 339.48486,\n",
      "       307.26495, 322.3136 , 317.79877, 284.44244, 284.93427, 323.6417 ,\n",
      "       305.36444, 324.73486, 324.74448, 278.62018, 327.69052, 286.8324 ,\n",
      "       312.60233, 285.03094, 315.81442, 340.30377, 324.19623, 284.95364,\n",
      "       321.16684, 273.0838 , 322.015  , 319.51202, 280.57764, 338.00574,\n",
      "       309.39603, 312.7056 , 276.2766 , 292.8344 , 274.6649 , 345.6399 ,\n",
      "       274.59937, 280.95172, 410.49445, 353.10712, 312.26465, 325.98953,\n",
      "       357.89804, 274.95764, 288.36517, 321.76846, 321.52167, 305.7489 ,\n",
      "       425.19177, 325.0089 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 170, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([314.7278 , 370.95023, 272.8417 , 342.15454, 309.2304 , 327.47293,\n",
      "       306.89975, 314.4666 , 316.9978 , 283.3715 , 284.14008, 322.25732,\n",
      "       303.58722, 323.43106, 324.03653, 277.93552, 325.6781 , 285.8793 ,\n",
      "       311.91656, 283.9949 , 315.08334, 340.30188, 322.98218, 283.94678,\n",
      "       320.33118, 272.44708, 321.0149 , 312.13245, 279.67084, 332.1039 ,\n",
      "       308.77817, 311.626  , 275.6384 , 291.21124, 273.43005, 339.4765 ,\n",
      "       273.9271 , 278.3105 , 390.75537, 345.7349 , 309.73517, 324.37958,\n",
      "       349.95813, 274.32745, 287.01932, 320.9368 , 320.5862 , 300.2076 ,\n",
      "       404.98474, 323.65594], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 180, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([312.701  , 361.15552, 272.22375, 330.21756, 301.1516 , 316.8859 ,\n",
      "       306.6263 , 307.6582 , 316.23526, 282.40637, 283.37802, 320.28967,\n",
      "       301.7212 , 322.20245, 323.3404 , 277.27048, 323.94864, 284.92728,\n",
      "       311.2469 , 283.07724, 314.36523, 340.29993, 321.83636, 283.09705,\n",
      "       319.5147 , 271.85736, 320.05377, 305.9856 , 278.8467 , 327.27533,\n",
      "       308.1731 , 310.68857, 275.014  , 289.6514 , 272.39084, 334.40808,\n",
      "       273.27744, 276.2048 , 374.35565, 339.60303, 307.81177, 322.92743,\n",
      "       343.3554 , 273.71664, 285.88818, 320.12418, 319.68268, 295.75964,\n",
      "       387.8836 , 322.4159 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 190, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([311.08112, 352.83334, 271.62976, 320.37494, 294.49683, 308.56512,\n",
      "       306.4244 , 302.02267, 315.5015 , 281.45386, 282.6399 , 318.78476,\n",
      "       299.8128 , 321.05316, 322.65298, 276.62155, 322.42648, 283.5031 ,\n",
      "       310.59073, 282.2257 , 313.662  , 340.29785, 320.74527, 282.3227 ,\n",
      "       318.7168 , 271.29102, 319.12695, 300.8789 , 278.08282, 323.3346 ,\n",
      "       307.57886, 309.85135, 274.4021 , 288.15756, 271.48767, 330.24887,\n",
      "       272.64667, 274.50726, 360.96985, 334.51788, 306.21823, 321.61572,\n",
      "       337.87085, 273.12112, 284.84076, 319.32846, 318.80756, 292.22388,\n",
      "       373.49005, 321.2503 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 200, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([309.75613, 345.7813 , 271.0503 , 312.28064, 289.0385 , 301.58633,\n",
      "       306.2771 , 297.6046 , 314.79102, 280.57153, 281.92084, 317.938  ,\n",
      "       297.87766, 319.96368, 321.97278, 275.98663, 321.0597 , 281.70386,\n",
      "       309.94708, 281.41495, 312.9737 , 340.2954 , 319.7013 , 281.58582,\n",
      "       317.9364 , 270.73788, 318.23184, 296.6405 , 277.36646, 320.1199 ,\n",
      "       306.995  , 309.08673, 273.8027 , 286.73138, 270.68   , 326.8352 ,\n",
      "       272.0321 , 273.1081 , 349.79813, 330.30658, 304.82605, 320.41144,\n",
      "       333.3136 , 272.5389 , 283.81293, 318.5466 , 317.95822, 289.34583,\n",
      "       361.4394 , 320.1439 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 210, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([308.64554, 339.81915, 270.4809 , 305.63696, 284.5567 , 295.72635,\n",
      "       306.171  , 294.153  , 314.09998, 279.71106, 281.2176 , 317.1424 ,\n",
      "       296.0177 , 318.92303, 321.29938, 275.3655 , 319.81195, 280.8977 ,\n",
      "       309.3147 , 280.63535, 312.29886, 340.29248, 318.69882, 280.87808,\n",
      "       317.17328, 270.19708, 317.36566, 293.11868, 276.67975, 317.49158,\n",
      "       306.41992, 308.37753, 273.2153 , 285.37347, 269.94138, 324.02545,\n",
      "       271.4319 , 271.93082, 340.5699 , 326.81705, 303.4157 , 319.2879 ,\n",
      "       329.51868, 271.96646, 282.80902, 316.96478, 317.13287, 286.97736,\n",
      "       351.39963, 319.08508], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 220, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([307.69202, 334.78638, 269.92407, 300.17932, 280.89465, 290.81985,\n",
      "       306.09552, 291.27554, 313.42596, 278.88422, 280.52884, 316.38605,\n",
      "       294.28198, 317.92474, 320.63312, 274.75717, 318.65845, 280.03674,\n",
      "       308.6933 , 279.87967, 311.63654, 340.28558, 317.73306, 280.18658,\n",
      "       316.42645, 269.66785, 316.52643, 290.18195, 276.01306, 315.33112,\n",
      "       305.8518 , 307.71228, 272.63962, 284.08328, 269.25403, 321.6989 ,\n",
      "       270.84595, 270.91516, 332.99704, 323.91675, 302.70285, 318.23038,\n",
      "       326.3446 , 271.3999 , 281.83395, 315.9289 , 316.33047, 285.01517,\n",
      "       343.07153, 318.05524], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 230, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([306.8546 , 330.54083, 269.37872, 295.68393, 277.89148, 286.7112 ,\n",
      "       306.0427 , 288.76782, 312.76746, 278.07883, 279.85297, 315.6413 ,\n",
      "       292.65698, 316.96393, 319.9745 , 274.1612 , 317.5805 , 279.27426,\n",
      "       308.08258, 279.1435 , 310.9867 , 340.22525, 316.80023, 279.51056,\n",
      "       315.6952 , 269.15045, 315.71222, 287.71838, 275.36203, 313.53967,\n",
      "       305.2993 , 307.08328, 272.076  , 282.85977, 268.6069 , 319.75494,\n",
      "       270.27335, 270.02087, 326.77887, 321.4926 , 302.14835, 317.22864,\n",
      "       323.6715 , 270.85034, 280.887  , 314.87698, 315.55054, 283.365  ,\n",
      "       336.18762, 317.0784 ], dtype=float32)\n",
      "  batch_dim = 0\n",
      "step 240, loss: Traced<ShapedArray(float32[])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([306.10376, 326.95795, 268.84424, 291.96066, 275.4235 , 283.2717 ,\n",
      "       306.00592, 286.56772, 312.12308, 277.29742, 279.18982, 314.91333,\n",
      "       291.13458, 316.03683, 319.3244 , 273.57745, 316.56534, 278.52368,\n",
      "       307.4824 , 278.42398, 310.34937, 339.29108, 315.89737, 278.84732,\n",
      "       314.97955, 268.6444 , 314.92163, 285.63403, 274.72546, 312.03638,\n",
      "       304.76483, 306.4847 , 271.52405, 281.70087, 267.99213, 318.11154,\n",
      "       269.7134 , 269.21674, 321.6714 , 319.4497 , 301.73904, 316.27444,\n",
      "       321.39996, 270.31665, 279.96765, 314.04718, 314.79254, 281.9599 ,\n",
      "       330.51093, 316.13593], dtype=float32)\n",
      "  batch_dim = 0\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data according to the wanted hyperparameters :\n",
    "n_bins_feedback = 10\n",
    "n_bins_action_angle = 8\n",
    "n_bins_action_position_per_dim = 3\n",
    "Nsteps = 250\n",
    "Nheads = 50\n",
    "head_init_window = [-20,20]\n",
    "\n",
    "rngkey = jr.PRNGKey(20)\n",
    "\n",
    "# If the points were too close, no angle was recorded :\n",
    "# The limit was arbitrrarily chosen at 7.5 :\n",
    "min_dist_norm = 7.5/(np.sqrt(2)*750)\n",
    "preprocessing_options = {\n",
    "    \"actions\":{\n",
    "        \"distance_bins\" : np.array([0.0,min_dist_norm,0.2,0.5,jnp.sqrt(2) + 1e-10]),\n",
    "        \"angle_N_bins\"  : n_bins_action_angle,\n",
    "        \"position_N_bins_per_dim\" : n_bins_action_position_per_dim\n",
    "    },\n",
    "    \"observations\":{\n",
    "        \"N_bins\" : n_bins_feedback,\n",
    "        \"observation_ends_at_point\" : 2\n",
    "    }\n",
    "}\n",
    "data = get_preprocessed_data_from_df(subjects_df,\n",
    "                            preprocessing_options,\n",
    "                            verbose=True,\n",
    "                            autosave=True,autoload=True,override_save=True,\n",
    "                            label=\"default\")\n",
    "\n",
    "\n",
    "\n",
    "# Get the data for one subject : \n",
    "subj_id = 10\n",
    "\n",
    "\n",
    "# The data to invert :\n",
    "formatted_stimuli= [data[\"observations\"][\"vect\"][1][subj_id]]\n",
    "bool_stimuli = [jnp.ones_like(stim[...,0]) for stim in formatted_stimuli] # Everything was seen :)\n",
    "rewards = jnp.array(data[\"observations\"][\"deltas\"])[subj_id]\n",
    "Ntrials,Nobservations = rewards.shape\n",
    "timesteps = jnp.broadcast_to(jnp.arange(Nobservations),(Ntrials,Nobservations))\n",
    "vect_actions = {}\n",
    "for key,val in data[\"actions\"][\"vect\"].items():\n",
    "    vect_actions[key] = jnp.array(val[subj_id])[:-1,:,:] # Ignore the last trial\n",
    "\n",
    "\n",
    "def get_models_from_options(_Nactions,_Nbins_feedback):\n",
    "    aif_th = 2  # Temporal horizon, big values will cause ballooning \n",
    "            # compilation times\n",
    "    Ns_latent = 5 # How many latent state in the subject model ?\n",
    "\n",
    "    aif_1D_static_params = {\n",
    "        # General environment : \n",
    "        \"N_feedback_ticks\":_Nbins_feedback,\n",
    "        # Latent state space structure\n",
    "        \"Ns_latent\":Ns_latent,      # For 1D\n",
    "        # Action discretization:\n",
    "        \"N_actions\" : _Nactions,\n",
    "        \n",
    "        \"Th\" : aif_th,\n",
    "        \n",
    "        \"learn_e\" : True\n",
    "    }\n",
    "\n",
    "    # Let's assume the following priors regarding the general models of the subjects : \n",
    "    # Overall uniform, with the following (weakly) informed priors :\n",
    "    # - high reward seeking\n",
    "    # - high action selection (inverse) temperature\n",
    "    # - low initial action concentration and stickiness (we focus only on the learning rate here)\n",
    "    # - high initial perception concentration\n",
    "    aif_1D_priors = {\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        # Model parameters : these should interact with the model components in a differentiable manner\n",
    "        \"transition_concentration\": tfd.Normal(1.0,0.5), # Initial concentrations should be rather low\n",
    "        \"transition_stickiness\": tfd.Normal(1.0,0.5),\n",
    "        \"transition_learning_rate\" : tfd.Uniform(low=-0.01,high=1000.0),\n",
    "        \"state_interpolation_temperature\" : tfd.Uniform(low=-0.01,high=10000.0),\n",
    "        \n",
    "        \"initial_state_concentration\": tfd.Uniform(low=-0.01,high=1000.0),\n",
    "        \n",
    "        \"feedback_expected_std\" : tfd.Uniform(low=-0.0,high=1000.0),\n",
    "        \"emission_concentration\" : tfd.Uniform(low=-0.01,high=1000.0),\n",
    "        \"emission_stickiness\" :  tfd.Normal(100.0,10.0),\n",
    "        \n",
    "        \"reward_seeking\" :tfd.Normal(10.0,10.0),\n",
    "        \"habits_learning_rate\" : tfd.Uniform(low=-0.01,high=1000.0),\n",
    "        \n",
    "        \"action_selection_temperature\" : tfd.Normal(10.0,1.0),\n",
    "    }\n",
    "    \n",
    "    comparison_index = {\n",
    "        \"random\":{\n",
    "            \"model\" : partial(random_agent,constants=(_Nactions,)),\n",
    "            \"priors\": None\n",
    "        },\n",
    "        \"rw\":{\n",
    "            \"model\" : partial(rescorla_wagner_agent,constants=(_Nactions,)),\n",
    "            \"priors\" : (tfd.Uniform(low=0.0,high=1.0),tfd.Normal(10.0,5.0))\n",
    "        },\n",
    "        \"ck\":{\n",
    "            \"model\" : partial(choice_kernel_agent,constants=(_Nactions,)),\n",
    "            \"priors\" : (tfd.Uniform(low=0.0,high=1.0),tfd.Normal(10.0,5.0))\n",
    "        },\n",
    "        \"rw_ck\":{\n",
    "            \"model\":partial(rw_ck_agent,constants=(_Nactions,)),\n",
    "            \"priors\": (tfd.Uniform(low=0.0,high=1.0),tfd.Normal(5.0,10.0),tfd.Uniform(low=0.0,high=1.0),tfd.Normal(5.0,10.0))\n",
    "        },\n",
    "        \"naive_qlearning\":{\n",
    "            \"model\":partial(q_learning_agent,constants=(_Nactions,_Nbins_feedback)),\n",
    "            \"priors\":(tfd.Uniform(low=0.0,high=1.0),tfd.Uniform(low=0.0,high=1.0),tfd.Normal(10.0,5.0),tfd.Uniform(low=0.0,high=1.0),tfd.Normal(10.0,5.0))\n",
    "        },\n",
    "        \"aif_1d\":{\n",
    "            \"model\":partial(active_inference_basic_1D,constants=aif_1D_static_params),\n",
    "            \"priors\":aif_1D_priors\n",
    "        }\n",
    "    }\n",
    "    return comparison_index\n",
    "\n",
    "subject_results_dict = {}\n",
    "for action_modality in [\"angle\"]:\n",
    "    modality_results_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    subject_data = (formatted_stimuli,bool_stimuli,rewards,vect_actions[action_modality],timesteps)\n",
    "    \n",
    "    model_index_for_action_modality = get_models_from_options(vect_actions[action_modality].shape[-1],n_bins_feedback)\n",
    "\n",
    "    for agent_name, agent_contents in model_index_for_action_modality.items():\n",
    "        print(\"     -> Agent : {}\".format(agent_name))\n",
    "        \n",
    "        agent = agent_contents[\"model\"]\n",
    "        agent_priors = agent_contents[\"priors\"]\n",
    "        \n",
    "        # Agent functions\n",
    "        _,_,_,_,_,encoder = agent(None)\n",
    "        def fit_agent(_data_one_subject,_fit_rng_key):  \n",
    "            \n",
    "            if agent_priors is None:\n",
    "                _n_params = 0\n",
    "                \n",
    "                _loss_history = None\n",
    "                _opt_vectors = None\n",
    "                \n",
    "                # We then compute the log-likelihoods of each solution for model comparison purposes :\n",
    "                _lls =  compute_loglikelihood(_data_one_subject,agent(None),'sum')\n",
    "                \n",
    "            else :\n",
    "                _n_params = len(agent_priors)\n",
    "                \n",
    "                # Multi-iteration based MAP : (we randomize the initial point and try to find minimas)\n",
    "                _opt_vectors,(_,_loss_history,_param_history),_encoding_function = fit_map_agent(_data_one_subject,agent,\n",
    "                                                                        _n_params,agent_priors,\n",
    "                                                                        _fit_rng_key,\n",
    "                                                                        true_hyperparams=None,verbose=True,                       \n",
    "                                                                        num_steps=Nsteps,n_iter=Nheads,initial_window=head_init_window)\n",
    "                \n",
    "                # We then compute the log-likelihoods of each solution for model comparison purposes :\n",
    "                _lls =   vmap(lambda x : compute_loglikelihood(_data_one_subject,agent(_encoding_function(x)),'sum'))(_opt_vectors)\n",
    "                    \n",
    "            return _loss_history,_opt_vectors,_lls\n",
    "\n",
    "        rngkey,local_key = jr.split(rngkey)\n",
    "        loss_histories,best_params,lls = fit_agent(subject_data,_fit_rng_key=local_key)\n",
    "\n",
    "        modality_results_dict[agent_name] = {\n",
    "            \"losses_hist\" : loss_histories,\n",
    "            \"params\" : best_params,\n",
    "            \"logliks\" : lls\n",
    "        }\n",
    "        \n",
    "        subject_results_dict[action_modality] = modality_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-190.67297 -190.4463  -198.42824 -198.43571 -197.00725 -197.11844\n",
      " -200.03658 -199.439   -190.08711 -197.05237 -200.00706 -189.83437\n",
      " -198.5281  -189.93663 -202.4051  -200.00961 -190.6494  -198.38045\n",
      " -190.04105 -196.11288 -190.26349 -190.18652 -189.99075 -199.66237\n",
      " -190.7037  -200.0065  -190.62558 -199.04529 -197.21788 -190.68213\n",
      " -190.8552  -190.62968 -200.00638 -199.84148 -197.32658 -190.70375\n",
      " -196.25739 -197.59981 -204.78429 -190.30774 -198.54152 -192.90549\n",
      " -190.02933 -199.9868  -199.833   -192.03499 -190.36116 -199.22256\n",
      " -190.09683 -189.99873]\n",
      "[-173.36174 -183.86942 -173.34084 -194.32878 -173.38957 -174.60852\n",
      " -173.28198 -186.46883 -173.36511 -173.3815  -173.36682 -173.37291\n",
      " -173.28008 -173.27531 -173.3555  -173.34781 -173.37268 -184.08997\n",
      " -173.36621 -173.37093 -173.28156 -173.3187  -173.30699 -184.08867\n",
      " -173.26859 -183.86926 -173.3474  -194.0538  -185.19997 -173.30447\n",
      " -173.27118 -173.27087 -173.2713  -173.32265 -173.26959 -173.36615\n",
      " -173.39299 -183.87285 -173.27669 -173.27109 -173.32709 -183.86934\n",
      " -173.37012 -173.33905 -194.4972  -173.3262  -173.27075 -173.2882\n",
      " -173.28986 -173.26985]\n",
      "[-173.36484 -167.74101 -167.81032 -167.84789 -167.74014 -173.36624\n",
      " -167.74583 -174.25995 -192.70566 -167.77083 -167.82788 -167.753\n",
      " -167.74014 -167.74028 -167.74779 -167.74318 -173.60347 -167.8427\n",
      " -167.74399 -167.74013 -167.74011 -167.75299 -169.45166 -167.91838\n",
      " -167.88388 -167.74103 -173.36484 -167.9231  -179.89957 -173.37115\n",
      " -179.53526 -167.75504 -167.83315 -167.8205  -167.75604 -167.85019\n",
      " -167.74011 -185.21143 -167.7521  -167.88019 -167.74016 -167.75725\n",
      " -167.74039 -173.36482 -167.82596 -167.74011 -167.7403  -167.74004\n",
      " -192.77399 -167.74182]\n",
      "[-192.70111 -195.91066 -195.90973 -192.70302 -192.70103 -192.70107\n",
      " -192.7011  -192.70073 -192.93353 -192.70107 -192.70107 -192.7011\n",
      " -192.70222 -192.70143 -192.70105 -192.70111 -195.91074 -195.91083\n",
      " -195.91084 -195.91063 -192.70563 -192.78575 -192.7037  -192.7011\n",
      " -195.91074 -192.70111 -195.91066 -192.70108 -192.7007  -193.14345\n",
      " -195.91052 -195.91066 -192.70108 -192.81606 -192.7011  -193.05286\n",
      " -192.70094 -192.70108 -192.7011  -195.91068 -192.70665 -192.70079\n",
      " -195.91068 -192.70287 -192.7011  -192.70428 -192.70271 -195.91064\n",
      " -192.71458 -192.7011 ]\n",
      "[-173.37231 -173.37178 -173.37253 -173.37546 -173.3721  -185.21373\n",
      " -173.37439 -173.37547 -173.37225 -173.37225 -173.3954  -173.384\n",
      " -174.42122 -173.37294 -173.37213 -173.37288 -190.95993 -173.37292\n",
      " -195.35573 -173.37276 -185.21274 -173.37288 -173.37508 -173.37288\n",
      " -173.36813 -185.21379 -173.3729  -195.27151 -173.37227 -178.01714\n",
      " -173.37338 -173.40286 -177.12436 -173.3893  -173.3729  -173.3735\n",
      " -173.36584 -173.37286 -185.21378 -173.3731  -173.37296 -173.55731\n",
      " -173.37233 -173.80629 -185.21378 -185.21379 -173.37291 -173.37782\n",
      " -173.3729  -173.37897]\n"
     ]
    }
   ],
   "source": [
    "print(subject_results_dict[\"angle\"][\"aif_1d\"][\"logliks\"])\n",
    "\n",
    "print(subject_results_dict[\"angle\"][\"naive_qlearning\"][\"logliks\"])\n",
    "\n",
    "print(subject_results_dict[\"angle\"][\"rw_ck\"][\"logliks\"])\n",
    "\n",
    "print(subject_results_dict[\"angle\"][\"rw\"][\"logliks\"])\n",
    "\n",
    "print(subject_results_dict[\"angle\"][\"ck\"][\"logliks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 11)\n",
      "{'transition_concentration': Array(1.2071325, dtype=float32), 'transition_stickiness': Array(1.453517, dtype=float32), 'transition_learning_rate': Array(8.594912e-08, dtype=float32), 'state_interpolation_temperature': Array(5.1480413e-08, dtype=float32), 'initial_state_concentration': Array(0.0018086, dtype=float32), 'feedback_expected_std': Array(0.9601711, dtype=float32), 'emission_concentration': Array(3.4872937, dtype=float32), 'emission_stickiness': Array(38.809868, dtype=float32), 'reward_seeking': Array(10.001418, dtype=float32), 'habits_learning_rate': Array(3.4734664, dtype=float32), 'action_selection_temperature': Array(0.62299526, dtype=float32)}\n",
      "{'transition_concentration': Array(3.0308037, dtype=float32), 'transition_stickiness': Array(1.0000764, dtype=float32), 'transition_learning_rate': Array(0.01039839, dtype=float32), 'state_interpolation_temperature': Array(0.03547411, dtype=float32), 'initial_state_concentration': Array(1.7511253e-08, dtype=float32), 'feedback_expected_std': Array(1.8444945e-08, dtype=float32), 'emission_concentration': Array(9.339541e-05, dtype=float32), 'emission_stickiness': Array(23.228651, dtype=float32), 'reward_seeking': Array(10.001406, dtype=float32), 'habits_learning_rate': Array(4.5626645, dtype=float32), 'action_selection_temperature': Array(0.5982931, dtype=float32)}\n",
      "{'transition_concentration': Array(1.0271776, dtype=float32), 'transition_stickiness': Array(0.97156024, dtype=float32), 'transition_learning_rate': Array(1.3557941, dtype=float32), 'state_interpolation_temperature': Array(1.7229586, dtype=float32), 'initial_state_concentration': Array(2.0227256, dtype=float32), 'feedback_expected_std': Array(1.8180884e-08, dtype=float32), 'emission_concentration': Array(19.061398, dtype=float32), 'emission_stickiness': Array(39.45705, dtype=float32), 'reward_seeking': Array(9.989895, dtype=float32), 'habits_learning_rate': Array(0.0038641, dtype=float32), 'action_selection_temperature': Array(9.973521, dtype=float32)}\n",
      "{'transition_concentration': Array(2.5353353, dtype=float32), 'transition_stickiness': Array(2.1668186, dtype=float32), 'transition_learning_rate': Array(3.2096446, dtype=float32), 'state_interpolation_temperature': Array(1.5310285, dtype=float32), 'initial_state_concentration': Array(13.229776, dtype=float32), 'feedback_expected_std': Array(0.00241042, dtype=float32), 'emission_concentration': Array(9.5646105, dtype=float32), 'emission_stickiness': Array(24.850494, dtype=float32), 'reward_seeking': Array(9.179707, dtype=float32), 'habits_learning_rate': Array(0.00603336, dtype=float32), 'action_selection_temperature': Array(7.4791384, dtype=float32)}\n",
      "{'transition_concentration': Array(1.0333922, dtype=float32), 'transition_stickiness': Array(2.6432917, dtype=float32), 'transition_learning_rate': Array(3.8964112, dtype=float32), 'state_interpolation_temperature': Array(1.551833, dtype=float32), 'initial_state_concentration': Array(0.03426138, dtype=float32), 'feedback_expected_std': Array(0.82259756, dtype=float32), 'emission_concentration': Array(0.00173992, dtype=float32), 'emission_stickiness': Array(37.892235, dtype=float32), 'reward_seeking': Array(11.345191, dtype=float32), 'habits_learning_rate': Array(0.00254578, dtype=float32), 'action_selection_temperature': Array(9.5183935, dtype=float32)}\n",
      "{'transition_concentration': Array(3.1711273, dtype=float32), 'transition_stickiness': Array(0.9947039, dtype=float32), 'transition_learning_rate': Array(11.963948, dtype=float32), 'state_interpolation_temperature': Array(6.8020506, dtype=float32), 'initial_state_concentration': Array(7.5762434, dtype=float32), 'feedback_expected_std': Array(0.8348232, dtype=float32), 'emission_concentration': Array(7.866012e-08, dtype=float32), 'emission_stickiness': Array(33.274796, dtype=float32), 'reward_seeking': Array(11.98418, dtype=float32), 'habits_learning_rate': Array(0.00209166, dtype=float32), 'action_selection_temperature': Array(10.010403, dtype=float32)}\n",
      "{'transition_concentration': Array(0.0001643, dtype=float32), 'transition_stickiness': Array(1.3653283e-09, dtype=float32), 'transition_learning_rate': Array(9.583164, dtype=float32), 'state_interpolation_temperature': Array(11.213997, dtype=float32), 'initial_state_concentration': Array(0.00039909, dtype=float32), 'feedback_expected_std': Array(2.9082581e-05, dtype=float32), 'emission_concentration': Array(0.00055873, dtype=float32), 'emission_stickiness': Array(0.00019939, dtype=float32), 'reward_seeking': Array(1.6469216, dtype=float32), 'habits_learning_rate': Array(0.00483055, dtype=float32), 'action_selection_temperature': Array(10.258022, dtype=float32)}\n",
      "{'transition_concentration': Array(0.9999799, dtype=float32), 'transition_stickiness': Array(2.1448722, dtype=float32), 'transition_learning_rate': Array(3.2805692e-05, dtype=float32), 'state_interpolation_temperature': Array(2.6082103, dtype=float32), 'initial_state_concentration': Array(18.309292, dtype=float32), 'feedback_expected_std': Array(0.00056709, dtype=float32), 'emission_concentration': Array(2.2609975e-06, dtype=float32), 'emission_stickiness': Array(40.99288, dtype=float32), 'reward_seeking': Array(10.005882, dtype=float32), 'habits_learning_rate': Array(0.0131455, dtype=float32), 'action_selection_temperature': Array(4.787131, dtype=float32)}\n",
      "{'transition_concentration': Array(1.0635892, dtype=float32), 'transition_stickiness': Array(0.9997966, dtype=float32), 'transition_learning_rate': Array(0.00721405, dtype=float32), 'state_interpolation_temperature': Array(9.664663, dtype=float32), 'initial_state_concentration': Array(0.00091014, dtype=float32), 'feedback_expected_std': Array(0.99968517, dtype=float32), 'emission_concentration': Array(4.186004, dtype=float32), 'emission_stickiness': Array(29.114996, dtype=float32), 'reward_seeking': Array(10.000115, dtype=float32), 'habits_learning_rate': Array(9.614507, dtype=float32), 'action_selection_temperature': Array(0.5437127, dtype=float32)}\n",
      "{'transition_concentration': Array(1.0267906, dtype=float32), 'transition_stickiness': Array(0.97174495, dtype=float32), 'transition_learning_rate': Array(2.94436, dtype=float32), 'state_interpolation_temperature': Array(11.017097, dtype=float32), 'initial_state_concentration': Array(0.00022973, dtype=float32), 'feedback_expected_std': Array(0.7747432, dtype=float32), 'emission_concentration': Array(6.517918e-06, dtype=float32), 'emission_stickiness': Array(25.27904, dtype=float32), 'reward_seeking': Array(10.416437, dtype=float32), 'habits_learning_rate': Array(0.00223987, dtype=float32), 'action_selection_temperature': Array(10.032067, dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "md = get_models_from_options(9,n_bins_feedback)\n",
    "\n",
    "_,_,_,_,_,encoder = md[\"aif_1d\"][\"model\"](None)\n",
    "\n",
    "print(subject_results_dict[\"angle\"][\"aif_1d\"][\"params\"].shape)\n",
    "for i in range(10):\n",
    "    print(encoder(subject_results_dict[\"angle\"][\"aif_1d\"][\"params\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the performances of the AIF agent : \n",
    "- Implement habit learning (expect a big difference for subjects like n0)\n",
    "- Test other preprocessing options\n",
    "- Implement temporary model updates during a trial\n",
    "\n",
    "Overall, it matches our expectations that a more model-less approach fits well simple learning paradigms, with a big nudge towards recurring behaviour (if you have chosen a specific action, you will be more likly to pick it again next time). What would be interestting would be :\n",
    "- a. Assuming some initial parameters, see how long each model takes to predict things correctly\n",
    "- b. Simulate the behaviour of these fitted agents given a new end position at the middle of the training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploit_results_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
